[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Machine Learning Fundamentals",
    "section": "",
    "text": "1 Challenge Summary\nYour organization wants to know which companies are similar to each other to help in identifying potential customers of a SAAS software solution (e.g. Salesforce CRM or equivalent) in various segments of the market. The Sales Department is very interested in this analysis, which will help them more easily penetrate various market segments.\nYou will be using stock prices in this analysis. You come up with a method to classify companies based on how their stocks trade using their daily stock returns (percentage movement from one day to the next). This analysis will help your organization determine which companies are related to each other (competitors and have similar attributes).\nYou can analyze the stock prices using what you’ve learned in the unsupervised learning tools including K-Means and UMAP. You will use a combination of kmeans() to find groups and umap() to visualize similarity of daily stock returns.\n\n2 Objectives\nApply your knowledge on K-Means and UMAP along with dplyr, ggplot2, and purrr to create a visualization that identifies subgroups in the S&P 500 Index. You will specifically apply:\n\nModeling: kmeans() and umap()\n\nIteration: purrr\n\nData Manipulation: dplyr, tidyr, and tibble\n\nVisualization: ggplot2 (bonus plotly)\n\n3 Libraries\nLoad the following libraries.\n\n# install.packages(\"plotly\")\n\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(broom)\nlibrary(umap)\n\nlibrary(magrittr)\nlibrary(dplyr)\n\n\n4 Data\nWe will be using stock prices in this analysis. Although some of you know already how to use an API to retrieve stock prices I obtained the stock prices for every stock in the S&P 500 index for you already. The files are saved in the session_6_data directory.\nWe can read in the stock prices. The data is 1.2M observations. The most important columns for our analysis are:\n\n\nsymbol: The stock ticker symbol that corresponds to a company’s stock price\n\ndate: The timestamp relating the symbol to the share price at that point in time\n\nadjusted: The stock price, adjusted for any splits and dividends (we use this when analyzing stock data over long periods of time)\n\n\n# STOCK PRICES\nsp_500_prices_tbl <- read_rds(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/sp_500_prices_tbl.rds\")\nsp_500_prices_tbl\n\n\n\n  \n\n\n\nThe second data frame contains information about the stocks the most important of which are:\n\n\ncompany: The company name\n\nsector: The sector that the company belongs to\n\n\n# SECTOR INFORMATION\nsp_500_index_tbl <- read_rds(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/sp_500_index_tbl.rds\")\nsp_500_index_tbl"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#header-2",
    "href": "content/01_journal/01_tidyverse.html#header-2",
    "title": "Machine Learning Fundamentals",
    "section": "\n6.1 Header 2",
    "text": "6.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Supervised ML - Regression (I) & Supervised ML - Regression (II)",
    "section": "",
    "text": "#Load all neccessary libraries\n\n# Standard\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n# Modeling\nlibrary(parsnip)\n\n# Preprocessing & Sampling\nlibrary(recipes)\n\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n\nlibrary(rsample)\n\n# Modeling Error Metrics\nlibrary(yardstick)\n\n#> \n#> Attaching package: 'yardstick'\n#> \n#> The following object is masked from 'package:readr':\n#> \n#>     spec\n\n# Plotting Decision Trees\nlibrary(rpart.plot)\n\n#> Loading required package: rpart\n\nlibrary(rsample)\nlibrary(parsnip)\nlibrary(yardstick)\nlibrary(workflows)\n\n\n1 Load the ‘bike_orderlines_tbl’ data from the specified file\n\nbike_orderlines_tbl <- readRDS(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/bike_orderlines.rds\")\nbike_orderlines_tbl\n\n\n\n  \n\n\n# Display the structure of the 'bike_orderlines_tbl' data\nglimpse(bike_orderlines_tbl)\n\n#> Rows: 15,644\n#> Columns: 18\n#> $ order_id       <dbl> 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7…\n#> $ order_line     <dbl> 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1…\n#> $ order_date     <dttm> 2015-01-07, 2015-01-07, 2015-01-10, 2015-01-10, 2015-0…\n#> $ model          <chr> \"Spectral CF 7 WMN\", \"Ultimate CF SLX Disc 8.0 ETAP\", \"…\n#> $ model_year     <dbl> 2021, 2020, 2021, 2019, 2020, 2020, 2020, 2021, 2020, 2…\n#> $ category_1     <chr> \"Mountain\", \"Road\", \"Mountain\", \"Road\", \"Mountain\", \"Hy…\n#> $ category_2     <chr> \"Trail\", \"Race\", \"Trail\", \"Triathlon Bike\", \"Dirt Jump\"…\n#> $ category_3     <chr> \"Spectral\", \"Ultimate\", \"Neuron\", \"Speedmax\", \"Stitched…\n#> $ price          <dbl> 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#> $ quantity       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1…\n#> $ total_price    <dbl> 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#> $ frame_material <chr> \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"aluminium\", \"c…\n#> $ weight         <dbl> 13.80, 7.44, 14.06, 8.80, 11.50, 8.80, 8.20, 8.85, 14.4…\n#> $ url            <chr> \"https://www.canyon.com/en-de/mountain-bikes/trail-bike…\n#> $ bikeshop       <chr> \"AlexandeRad\", \"AlexandeRad\", \"WITT-RAD\", \"WITT-RAD\", \"…\n#> $ location       <chr> \"Hamburg, Hamburg\", \"Hamburg, Hamburg\", \"Bremen, Bremen…\n#> $ lat            <dbl> 53.57532, 53.57532, 53.07379, 53.07379, 48.78234, 48.78…\n#> $ lng            <dbl> 10.015340, 10.015340, 8.826754, 8.826754, 9.180819, 9.1…\n\n#Create new table\nmodel_sales_tbl <- bike_orderlines_tbl %>%\n\n    #Select: total price, model, category_2 and frame material\n    select(total_price, model, category_2, frame_material) %>%\n    \n    # Group the data by 'model', 'category_2', and 'frame_material'\n    group_by(model, category_2, frame_material) %>%\n    \n    # Calculate the total sales for each combination of 'model', 'category_2', and 'frame_material'\n    summarise(total_sales = sum(total_price)) %>%\n\n    # Ungroup the data\n    ungroup() %>%\n   \n    # Arrange the data in descending order of 'total_sales'\n    arrange(desc(total_sales))\n\n#> `summarise()` has grouped output by 'model', 'category_2'. You can override\n#> using the `.groups` argument.\n\n# Modify the 'category_2' column in 'model_sales_tbl' to reorder the levels based on 'total_sales'\nmodel_sales_tbl %>%\n    mutate(category_2 = as_factor(category_2) %>% \n               fct_reorder(total_sales, .fun = max) %>% \n               fct_rev()) %>%\n  \n    \n    # Create a violin plot with 'frame_material' on the x-axis and 'total_sales' on the y-axis\n    ggplot(aes(frame_material, total_sales)) +\n    geom_violin() +  # Add violin plot\n    geom_jitter(width = 0.1, alpha = 0.5, color = \"#2c3e50\") +  # Add jittered points\n    facet_wrap(~ category_2) +  # Create separate facets for each 'category_2'\n    scale_y_continuous(labels = scales::dollar_format(scale = 1e-6, suffix = \"M\", accuracy = 0.1)) +  # Format y-axis labels as dollars in millions\n    tidyquant::theme_tq() +  # Apply a theme from the tidyquant package\n    labs(\n        title = \"Total Sales for Each Model\",  # Set the title of the plot\n        x = \"Frame Material\", y = \"Revenue\"  # Set the axis labels\n    )\n\n#> Registered S3 method overwritten by 'quantmod':\n#>   method            from\n#>   as.zoo.data.frame zoo\n\n\n#> Warning: Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n\n\n#> Warning in max(data$density): no non-missing arguments to max; returning -Inf\n\n\n#> Warning: Computation failed in `stat_ydensity()`\n#> Caused by error in `$<-.data.frame`:\n#> ! replacement has 1 row, data has 0\n\n\n\n\n\n\n\n\n#Data Preparation\n\nbike_features_tbl <- readRDS(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/bike_features_tbl.rds\")\nglimpse(bike_features_tbl)\n\n#> Rows: 231\n#> Columns: 67\n#> $ bike_id                     <dbl> 2875, 2873, 2874, 2876, 2877, 2225, 2091, …\n#> $ model                       <chr> \"Aeroad CF SL Disc 8.0 Di2\", \"Aeroad CF SL…\n#> $ model_year                  <dbl> 2020, 2020, 2020, 2020, 2020, 2019, 2019, …\n#> $ frame_material              <chr> \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"c…\n#> $ weight                      <dbl> 7.60, 7.27, 7.10, 7.73, 7.83, 6.80, 6.80, …\n#> $ price                       <dbl> 4579, 6919, 6429, 5069, 3609, 6139, 5359, …\n#> $ category_1                  <chr> \"Road\", \"Road\", \"Road\", \"Road\", \"Road\", \"R…\n#> $ category_2                  <chr> \"Race\", \"Race\", \"Race\", \"Race\", \"Race\", \"R…\n#> $ category_3                  <chr> \"Aeroad\", \"Aeroad\", \"Aeroad\", \"Aeroad\", \"A…\n#> $ gender                      <chr> \"unisex\", \"unisex\", \"unisex\", \"unisex\", \"u…\n#> $ url                         <chr> \"https://www.canyon.com/en-de/road-bikes/r…\n#> $ Frame                       <chr> \"Canyon Aeroad CF SL Disc\", \"Canyon Aeroad…\n#> $ Fork                        <chr> \"Canyon FK0041 CF SLX Disc\", \"Canyon FK004…\n#> $ `Rear Derailleur`           <chr> \"Shimano Ultegra Di2 R8050 SS\", \"SRAM RED …\n#> $ `Front Derailleur`          <chr> \"Shimano Ultegra Di2 R8050\", \"SRAM RED eTa…\n#> $ Cassette                    <chr> \"Shimano Ultegra R8000, 11-speed, 11-28T\",…\n#> $ Crank                       <chr> \"Shimano Ultegra R8000\", \"SRAM RED D1\", \"S…\n#> $ `Bottom bracket`            <chr> \"Shimano Pressfit BB72\", \"SRAM Pressfit RE…\n#> $ `Thru Axle`                 <chr> \"Canyon Thru Axle\", \"Canyon Thru Axle\", \"C…\n#> $ Cockpit                     <chr> \"Canyon H36 Aerocockpit CF\", \"Canyon H36 A…\n#> $ Saddle                      <chr> \"Selle Italia SLR\", \"Selle Italia SLR\", \"S…\n#> $ Seatpost                    <chr> \"Canyon S27 Aero VCLS CF\", \"Canyon S27 Aer…\n#> $ Pedals                      <chr> \"None included\", \"None included\", \"None in…\n#> $ `Derailleur hanger`         <chr> \"Shop Derailleur Hanger GP0211-01\", \"Shop …\n#> $ Battery                     <chr> \"\", \"SRAM eTap Powerpack\", \"\", \"SRAM eTap …\n#> $ Brake                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Shift Lever`               <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"Shimano Di2 Remot…\n#> $ Chain                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"Shimano CN-HG901 …\n#> $ Stem                        <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Canyon V13\", …\n#> $ Handlebar                   <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Canyon H16 Ae…\n#> $ Headset                     <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Motor                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Battery Charger`           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Flat Pedals`               <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Chainguard                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Aero Bar`                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake Lever / Master`      <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Wheel Tire System`         <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Suspension Fork`           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Disc Brake`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Grips                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Chainring                   <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Display                     <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Modeswitch                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Rear Shock`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Light                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Fender                      <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Bike Racks`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake 1`                   <chr> \"\", \"\", \"\", \"\", \"\", \"SRAM S-900 Direct Mou…\n#> $ `Brake 2`                   <chr> \"\", \"\", \"\", \"\", \"\", \"SRAM S-900 Direct Mou…\n#> $ `Shift-/ Brake Lever 1`     <chr> \"Shimano Ultegra Di2 R8070, 11-speed\", \"SR…\n#> $ `Shift-/ Brake Lever 2`     <chr> \"Shimano Ultegra Di2 R8070, 11-speed\", \"SR…\n#> $ `Wheel 1`                   <chr> \"DT Swiss ARC 1400 Dicut\", \"DT Swiss ARC 1…\n#> $ `Wheel 2`                   <chr> \"DT Swiss ARC 1400 Dicut\", \"DT Swiss ARC 1…\n#> $ `Tyre 1`                    <chr> \"Continental Grand Prix 5000 / Attack  23 …\n#> $ `Tyre 2`                    <chr> \"Continental Grand Prix 5000, 25 mm\", \"Con…\n#> $ `Handlebar Tape 1`          <chr> \"Canyon Ergospeed Gel\", \"Canyon Ergospeed …\n#> $ `Handlebar Tape 2`          <chr> \"Canyon bar-end plug\", \"Canyon bar-end plu…\n#> $ `Manuals and Accessories 1` <chr> \"Canyon tool case\", \"Canyon tool case\", \"C…\n#> $ `Manuals and Accessories 2` <chr> \"DT Swiss warranty & intended use manual\",…\n#> $ `Manuals and Accessories 3` <chr> \"Canyon starter box\", \"Canyon starter box\"…\n#> $ `Manuals and Accessories 4` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"BAG R…\n#> $ `Manuals and Accessories 5` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 6` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 7` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 8` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake Rotor`               <list> \"Shimano RT800\", \"SRAM Centerline X\", \"Sh…\n\nbike_features_tbl\n\n\n\n  \n\n\nbike_features_tbl <- bike_features_tbl %>% \n    select(model:url, `Rear Derailleur`, `Shift Lever`) %>% \n    mutate(\n      `shimano dura-ace`        = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano dura-ace \") %>% as.numeric(),\n      `shimano ultegra`         = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano ultegra \") %>% as.numeric(),\n      `shimano 105`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano 105 \") %>% as.numeric(),\n      `shimano tiagra`          = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano tiagra \") %>% as.numeric(),\n      `Shimano sora`            = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano sora\") %>% as.numeric(),\n      `shimano deore`           = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano deore(?! xt)\") %>% as.numeric(),\n      `shimano slx`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano slx\") %>% as.numeric(),\n      `shimano grx`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano grx\") %>% as.numeric(),\n      `Shimano xt`              = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano deore xt |shimano xt \") %>% as.numeric(),\n      `Shimano xtr`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano xtr\") %>% as.numeric(),\n      `Shimano saint`           = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano saint\") %>% as.numeric(),\n      `SRAM red`                = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram red\") %>% as.numeric(),\n      `SRAM force`              = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram force\") %>% as.numeric(),\n      `SRAM rival`              = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram rival\") %>% as.numeric(),\n      `SRAM apex`               = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram apex\") %>% as.numeric(),\n      `SRAM xx1`                = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram xx1\") %>% as.numeric(),\n      `SRAM x01`                = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram x01|sram xo1\") %>% as.numeric(),\n      `SRAM gx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram gx\") %>% as.numeric(),\n      `SRAM nx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram nx\") %>% as.numeric(),\n      `SRAM sx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram sx\") %>% as.numeric(),\n      `SRAM sx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram sx\") %>% as.numeric(),\n      `Campagnolo potenza`      = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"campagnolo potenza\") %>% as.numeric(),\n      `Campagnolo super record` = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"campagnolo super record\") %>% as.numeric(),\n      `shimano nexus`           = `Shift Lever`     %>% str_to_lower() %>% str_detect(\"shimano nexus\") %>% as.numeric(),\n      `shimano alfine`          = `Shift Lever`     %>% str_to_lower() %>% str_detect(\"shimano alfine\") %>% as.numeric()\n    ) %>% \n  # Remove original columns  \n  select(-c(`Rear Derailleur`, `Shift Lever`)) %>% \n  # Set all NAs to 0\n  mutate_if(is.numeric, ~replace(., is.na(.), 0))\n\n#bike_features_tbl\n\n\n2 Let’s order and tidy the tibble a bit. We need the following data:\n\n# 2.0 TRAINING & TEST SETS ----\n\nbike_features_tbl <- bike_features_tbl %>% \n  \n  mutate(id = row_number()) %>% \n  \n  select(id, everything())\nbike_features_tbl\n\n\n\n  \n\n\n\n\n3 split data in test and train set (randomly)\n\n# Filter E-Road because it caused problems (just 1 element, and it could no be in training and test -> error bc not known)\nbike_features_tbl <- bike_features_tbl %>%\n  filter(category_2 != \"E-Road\")\n\nbike_features_tbl %>% distinct(category_2)\n\n\n\n  \n\n\nsum(bike_features_tbl$category_2 == \"E-Road\")\n\n#> [1] 0\n\n# run both following commands at the same time\nset.seed(seed = 1113)\n\nsplit_obj <- initial_split(bike_features_tbl, prop = 0.80, strata = \"category_2\")\n\n# Check if testing contains all category_2 values\nsplit_obj %>% training() %>% distinct(category_2)\n\n\n\n  \n\n\nsplit_obj %>% testing() %>% distinct(category_2)\n\n\n\n  \n\n\n# Assign training and test data\ntrain_tbl <- training(split_obj)\ntest_tbl  <- testing(split_obj)\n\n# We have to remove spaces and dashes from the column names\ntrain_tbl <- train_tbl %>% set_names(str_replace_all(names(train_tbl), \" |-\", \"_\"))\ntest_tbl  <- test_tbl  %>% set_names(str_replace_all(names(test_tbl),  \" |-\", \"_\"))\n\n\n4 Linear Regression Model and prediction (bad result due to not well choosen features)\n\nmodel_01_linear_lm_simple <- linear_reg(mode = \"regression\") %>%\n    set_engine(\"lm\") %>%\n    fit(price ~ category_2 + frame_material, data = train_tbl)\ntest_tbl\n\n\n\n  \n\n\nmodel_01_linear_lm_simple %>%\n    predict(new_data = test_tbl)%>%\n\n    bind_cols(test_tbl %>% select(price)) %>%\n  \n    yardstick::metrics(truth = price, estimate = .pred)\n\n\n\n  \n\n\n\n\n5 New Bike to predict price (use simpel model with bad prediction (since I had some issues with the engineered features)\n\n# 5.1 NEW MODEL ----\n\nnew_cross_country <- tibble(\n        model = \"Exceed AL SL new\",\n        category_2 = \"Cross-Country\",\n        frame_material = \"aluminium\",\n        shimano_dura_ace = 0,\n        shimano_ultegra = 0,\n        shimano_105 = 0,\n        shimano_tiagra = 0,\n        Shimano_sora = 0,\n        shimano_deore = 0,\n        shimano_slx = 0,\n        shimano_grx = 0,\n        Shimano_xt = 1,\n        Shimano_xtr = 0,\n        Shimano_saint = 0,\n        SRAM_red = 0,\n        SRAM_force = 0,\n        SRAM_rival = 0,\n        SRAM_apex = 0,\n        SRAM_xx1 = 0,\n        SRAM_x01 = 0,\n        SRAM_gx = 0,\n        SRAM_nx = 0,\n        SRAM_sx = 0,\n        Campagnolo_potenza = 0,\n        Campagnolo_super_record = 0,\n        shimano_nexus = 0,\n        shimano_alfine = 0\n) \n\nnew_cross_country\n\n\n\n  \n\n\npredict(model_01_linear_lm_simple,, new_data = new_cross_country)\n\n\n\n  \n\n\n\n\n6 engineered feature for better prediction\n\n# 3.2.1 Model ----\nmodel_02_linear_lm_complex <- linear_reg(\"regression\") %>%\n    set_engine(\"lm\") %>%\n    \n    # This is going to be different. Remove unnecessary columns.\n    fit(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender)))\n\n#model_02_linear_lm_complex %>% calc_metrics(new_data = test_tbl)\n\n#1 CHALLENGE WITH RECIPES PACKAGE:\n\n# define the model\nlm_model_spec <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  set_mode(\"regression\")\n\n#2\n\nrecipe_obj <- recipe(price ~ ., data = train_tbl) %>%\n  step_rm(id, url, model) %>%\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%\n  prep()\n\n# Apply preprocessing features to train and test data\ntrain_transformed_tbl <- bake(recipe_obj, new_data = train_tbl)\ntest_transformed_tbl  <- bake(recipe_obj, new_data = test_tbl)\n\n# Combine in workflow\nworkflow_obj <- workflow() %>%\n  add_recipe(recipe_obj) %>%\n  add_model(lm_model_spec) %>%\n  fit(data = train_tbl)\n\n# make predictions\npredictions <- predict(workflow_obj, new_data = test_tbl)\n\n#> Warning in predict.lm(object = object$fit, newdata = new_data, type =\n#> \"response\"): prediction from a rank-deficient fit may be misleading\n\n\n\n# Combine predictions with actual prices\npredictions_with_actual <- bind_cols(test_transformed_tbl %>% select(price), predictions)\n\n# Calculate evaluation metrics\nevaluation_metrics <- yardstick::metrics(predictions_with_actual, truth = price, estimate = .pred)\n\n# Print evaluation metrics\nprint(evaluation_metrics)\n\n#> # A tibble: 3 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard    1073.   \n#> 2 rsq     standard       0.523\n#> 3 mae     standard     771."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "",
    "text": "#install.packages(\"h2o\")\nlibrary(h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n\n\n#> \n#> Attaching package: 'h2o'\n\n\n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n\n\n#> The following objects are masked from 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n\n# To launch H2O locally with default initialization arguments, use the following: \nh2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         30 minutes 21 seconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.55 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#load-the-training-test-dataset",
    "href": "content/01_journal/03_data_wrangling.html#load-the-training-test-dataset",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.1 1. Load the training & test dataset",
    "text": "1.1 1. Load the training & test dataset\n\n# Required Libraries\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ lubridate::day()   masks h2o::day()\n#> ✖ dplyr::filter()    masks stats::filter()\n#> ✖ lubridate::hour()  masks h2o::hour()\n#> ✖ dplyr::lag()       masks stats::lag()\n#> ✖ lubridate::month() masks h2o::month()\n#> ✖ lubridate::week()  masks h2o::week()\n#> ✖ lubridate::year()  masks h2o::year()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(recipes)\n\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n\nlibrary(rsample)\nlibrary(h2o)\n\n\n# Initialize H2O\nh2o_connection <- h2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         30 minutes 25 seconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.55 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n\n# Read and Split Data\nproduct_backorders_tbl <- read_csv(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/product_backorders.csv\")\n\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#test print\n#product_backorders_tbl\nset_seed <- 1113\nsplit_obj <- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_data_tbl <- training(split_obj)\ntest_data_tbl <- testing(split_obj)\n\n# Data Preparation\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_data_tbl) %>%\n  step_zv(all_predictors()) %>%\n  prep()\n\ntrain_prepared_tbl <- bake(recipe_obj, new_data = train_data_tbl)\ntest_prepared_tbl <- bake(recipe_obj, new_data = test_data_tbl)\n#train_prepared_tbl\n#test_prepared_tbl"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#specifiy-the-response-and-predictor-variables",
    "href": "content/01_journal/03_data_wrangling.html#specifiy-the-response-and-predictor-variables",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.2 2.Specifiy the response and predictor variables",
    "text": "1.2 2.Specifiy the response and predictor variables\n\n# Divide the data into a training and a validation data frame\n# The seed is set for the sake of reproducibility\nsplit_h2o <- h2o.splitFrame(as.h2o(train_prepared_tbl), ratios = c(0.85), seed = 1234)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_prepared_tbl)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Define the response variable\ntarget_variable <- \"went_on_backorder\"\n\n# Define the predictor variables\nfeature_variables <- setdiff(names(train_h2o), target_variable)"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#run-automl-specifying-the-stopping-criterion",
    "href": "content/01_journal/03_data_wrangling.html#run-automl-specifying-the-stopping-criterion",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.3 3 run AutoML specifying the stopping criterion",
    "text": "1.3 3 run AutoML specifying the stopping criterion\n\n# Run automated machine learning\nautoml_model_h2o <- h2o.automl(\n  x = feature_variables,\n  y = target_variable,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs = 30,\n  nfolds = 5\n)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n#> 06:55:07.537: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 06:55:07.540: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |======================================================================| 100%\n\n#train_h2o\n#valid_h2o\n#test_h2o\n# Check the type of the automl_model_h2o object\nmodel_type <- typeof(automl_model_h2o)\n\n#model_type"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#view-the-leaderboard-5.save-the-leader-model-6.load-the-model",
    "href": "content/01_journal/03_data_wrangling.html#view-the-leaderboard-5.save-the-leader-model-6.load-the-model",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.4 4. View the leaderboard 5.Save the leader model 6.Load the model",
    "text": "1.4 4. View the leaderboard 5.Save the leader model 6.Load the model\n\n# Get the names of slots in the automl_models_h2o object\nslots <- slotNames(automl_model_h2o)\n\n# Access the leaderboard from the automl_models_h2o object\nleaderboard <- automl_model_h2o@leaderboard\nleaderboard\n\n#>                                                 model_id       auc   logloss\n#> 1 StackedEnsemble_BestOfFamily_3_AutoML_4_20230615_65507 0.9548752 0.1624372\n#> 2 StackedEnsemble_BestOfFamily_2_AutoML_4_20230615_65507 0.9543220 0.1629562\n#> 3    StackedEnsemble_AllModels_2_AutoML_4_20230615_65507 0.9524745 0.1639352\n#> 4    StackedEnsemble_AllModels_1_AutoML_4_20230615_65507 0.9520404 0.1643658\n#> 5                          GBM_4_AutoML_4_20230615_65507 0.9506423 0.1666743\n#> 6                          GBM_3_AutoML_4_20230615_65507 0.9484670 0.1698379\n#>       aucpr mean_per_class_error      rmse        mse\n#> 1 0.7226072            0.1578775 0.2212378 0.04894618\n#> 2 0.7211075            0.1564502 0.2213882 0.04901273\n#> 3 0.7164268            0.1468513 0.2223098 0.04942165\n#> 4 0.7161839            0.1392679 0.2223394 0.04943483\n#> 5 0.7110763            0.1471887 0.2229243 0.04969525\n#> 6 0.7093239            0.1541291 0.2249658 0.05060962\n#> \n#> [14 rows x 7 columns]\n\n\n\n# Extract the name of a specific model from the leaderboard\nget_model_name <- function(h2o_leaderboard, n = 1, verbose = T) {\n  \n  model_name <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(n) %>%\n    pull(model_id)\n  \n  if (verbose) message(model_name)\n  \n  return(model_name)\n  \n}\n\n# Get the name of the 6th model in the leaderboard\nmodel_name <- automl_model_h2o@leaderboard %>% \n  get_model_name(1) %>% \n  h2o.getModel()\n\n#> StackedEnsemble_BestOfFamily_3_AutoML_4_20230615_65507\n\n# Save the specified model\n#h2o.getModel(\"StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\") %>% \n#h2o.saveModel(path = \"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/\")\n\n\n# Load a specific model\nloaded_model <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\")"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#predicting-using-leader-model",
    "href": "content/01_journal/03_data_wrangling.html#predicting-using-leader-model",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.5 5.Predicting using Leader Model",
    "text": "1.5 5.Predicting using Leader Model\n\n# Generate predictions using the Stacked Ensemble model\npredictions <- h2o.predict(loaded_model, newdata = as.h2o(test_h2o))\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Check the type of the predictions object\npred_type <- typeof(predictions)\n\n# Convert predictions to a tibble\npredictions_tbl <- as_tibble(predictions)\nView(predictions_tbl)"
  },
  {
    "objectID": "content/01_journal/01_Challenge1_Machine_Learning_Fundamentals.html",
    "href": "content/01_journal/01_Challenge1_Machine_Learning_Fundamentals.html",
    "title": "Machine Learning Fundamentals",
    "section": "",
    "text": "1 Challenge Summary\nYour organization wants to know which companies are similar to each other to help in identifying potential customers of a SAAS software solution (e.g. Salesforce CRM or equivalent) in various segments of the market. The Sales Department is very interested in this analysis, which will help them more easily penetrate various market segments.\nYou will be using stock prices in this analysis. You come up with a method to classify companies based on how their stocks trade using their daily stock returns (percentage movement from one day to the next). This analysis will help your organization determine which companies are related to each other (competitors and have similar attributes).\nYou can analyze the stock prices using what you’ve learned in the unsupervised learning tools including K-Means and UMAP. You will use a combination of kmeans() to find groups and umap() to visualize similarity of daily stock returns.\n\n2 Objectives\nApply your knowledge on K-Means and UMAP along with dplyr, ggplot2, and purrr to create a visualization that identifies subgroups in the S&P 500 Index. You will specifically apply:\n\nModeling: kmeans() and umap()\n\nIteration: purrr\n\nData Manipulation: dplyr, tidyr, and tibble\n\nVisualization: ggplot2 (bonus plotly)\n\n3 Libraries\nLoad the following libraries.\n\n# install.packages(\"plotly\")\n\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(tidyquant)\n\n#> Loading required package: PerformanceAnalytics\n#> Loading required package: xts\n#> Loading required package: zoo\n#> \n#> Attaching package: 'zoo'\n#> \n#> The following objects are masked from 'package:base':\n#> \n#>     as.Date, as.Date.numeric\n#> \n#> \n#> ######################### Warning from 'xts' package ##########################\n#> #                                                                             #\n#> # The dplyr lag() function breaks how base R's lag() function is supposed to  #\n#> # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n#> # source() into this session won't work correctly.                            #\n#> #                                                                             #\n#> # Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n#> # conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n#> # dplyr from breaking base R's lag() function.                                #\n#> #                                                                             #\n#> # Code in packages is not affected. It's protected by R's namespace mechanism #\n#> # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#> #                                                                             #\n#> ###############################################################################\n#> \n#> Attaching package: 'xts'\n#> \n#> The following objects are masked from 'package:dplyr':\n#> \n#>     first, last\n#> \n#> \n#> Attaching package: 'PerformanceAnalytics'\n#> \n#> The following object is masked from 'package:graphics':\n#> \n#>     legend\n#> \n#> Loading required package: quantmod\n#> Loading required package: TTR\n#> Registered S3 method overwritten by 'quantmod':\n#>   method            from\n#>   as.zoo.data.frame zoo\n\nlibrary(broom)\nlibrary(umap)\n\nlibrary(magrittr)\n\n#> \n#> Attaching package: 'magrittr'\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     set_names\n#> \n#> The following object is masked from 'package:tidyr':\n#> \n#>     extract\n\nlibrary(dplyr)\n\n\n4 Data\nWe will be using stock prices in this analysis. Although some of you know already how to use an API to retrieve stock prices I obtained the stock prices for every stock in the S&P 500 index for you already. The files are saved in the session_6_data directory.\nWe can read in the stock prices. The data is 1.2M observations. The most important columns for our analysis are:\n\n\nsymbol: The stock ticker symbol that corresponds to a company’s stock price\n\ndate: The timestamp relating the symbol to the share price at that point in time\n\nadjusted: The stock price, adjusted for any splits and dividends (we use this when analyzing stock data over long periods of time)\n\n\n# STOCK PRICES\nsp_500_prices_tbl <- read_rds(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/sp_500_prices_tbl.rds\")\nsp_500_prices_tbl\n\n\n\n  \n\n\n\nThe second data frame contains information about the stocks the most important of which are:\n\n\ncompany: The company name\n\nsector: The sector that the company belongs to\n\n\n# SECTOR INFORMATION\nsp_500_index_tbl <- read_rds(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/sp_500_index_tbl.rds\")\nsp_500_index_tbl"
  },
  {
    "objectID": "content/01_journal/02_Challenge2_Supervised_ML-Regression2.html",
    "href": "content/01_journal/02_Challenge2_Supervised_ML-Regression2.html",
    "title": "Supervised ML - Regression (I) & Supervised ML - Regression (II)",
    "section": "",
    "text": "#Load all neccessary libraries\n\n# Standard\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n# Modeling\nlibrary(parsnip)\n\n# Preprocessing & Sampling\nlibrary(recipes)\n\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n\nlibrary(rsample)\n\n# Modeling Error Metrics\nlibrary(yardstick)\n\n#> \n#> Attaching package: 'yardstick'\n#> \n#> The following object is masked from 'package:readr':\n#> \n#>     spec\n\n# Plotting Decision Trees\nlibrary(rpart.plot)\n\n#> Loading required package: rpart\n\nlibrary(rsample)\nlibrary(parsnip)\nlibrary(yardstick)\nlibrary(workflows)\n\n\n1 Load the ‘bike_orderlines_tbl’ data from the specified file\n\nbike_orderlines_tbl <- readRDS(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/bike_orderlines.rds\")\nbike_orderlines_tbl\n\n\n\n  \n\n\n# Display the structure of the 'bike_orderlines_tbl' data\nglimpse(bike_orderlines_tbl)\n\n#> Rows: 15,644\n#> Columns: 18\n#> $ order_id       <dbl> 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7…\n#> $ order_line     <dbl> 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1…\n#> $ order_date     <dttm> 2015-01-07, 2015-01-07, 2015-01-10, 2015-01-10, 2015-0…\n#> $ model          <chr> \"Spectral CF 7 WMN\", \"Ultimate CF SLX Disc 8.0 ETAP\", \"…\n#> $ model_year     <dbl> 2021, 2020, 2021, 2019, 2020, 2020, 2020, 2021, 2020, 2…\n#> $ category_1     <chr> \"Mountain\", \"Road\", \"Mountain\", \"Road\", \"Mountain\", \"Hy…\n#> $ category_2     <chr> \"Trail\", \"Race\", \"Trail\", \"Triathlon Bike\", \"Dirt Jump\"…\n#> $ category_3     <chr> \"Spectral\", \"Ultimate\", \"Neuron\", \"Speedmax\", \"Stitched…\n#> $ price          <dbl> 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#> $ quantity       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1…\n#> $ total_price    <dbl> 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#> $ frame_material <chr> \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"aluminium\", \"c…\n#> $ weight         <dbl> 13.80, 7.44, 14.06, 8.80, 11.50, 8.80, 8.20, 8.85, 14.4…\n#> $ url            <chr> \"https://www.canyon.com/en-de/mountain-bikes/trail-bike…\n#> $ bikeshop       <chr> \"AlexandeRad\", \"AlexandeRad\", \"WITT-RAD\", \"WITT-RAD\", \"…\n#> $ location       <chr> \"Hamburg, Hamburg\", \"Hamburg, Hamburg\", \"Bremen, Bremen…\n#> $ lat            <dbl> 53.57532, 53.57532, 53.07379, 53.07379, 48.78234, 48.78…\n#> $ lng            <dbl> 10.015340, 10.015340, 8.826754, 8.826754, 9.180819, 9.1…\n\n#Create new table\nmodel_sales_tbl <- bike_orderlines_tbl %>%\n\n    #Select: total price, model, category_2 and frame material\n    select(total_price, model, category_2, frame_material) %>%\n    \n    # Group the data by 'model', 'category_2', and 'frame_material'\n    group_by(model, category_2, frame_material) %>%\n    \n    # Calculate the total sales for each combination of 'model', 'category_2', and 'frame_material'\n    summarise(total_sales = sum(total_price)) %>%\n\n    # Ungroup the data\n    ungroup() %>%\n   \n    # Arrange the data in descending order of 'total_sales'\n    arrange(desc(total_sales))\n\n#> `summarise()` has grouped output by 'model', 'category_2'. You can override\n#> using the `.groups` argument.\n\n# Modify the 'category_2' column in 'model_sales_tbl' to reorder the levels based on 'total_sales'\nmodel_sales_tbl %>%\n    mutate(category_2 = as_factor(category_2) %>% \n               fct_reorder(total_sales, .fun = max) %>% \n               fct_rev()) %>%\n  \n    \n    # Create a violin plot with 'frame_material' on the x-axis and 'total_sales' on the y-axis\n    ggplot(aes(frame_material, total_sales)) +\n    geom_violin() +  # Add violin plot\n    geom_jitter(width = 0.1, alpha = 0.5, color = \"#2c3e50\") +  # Add jittered points\n    facet_wrap(~ category_2) +  # Create separate facets for each 'category_2'\n    scale_y_continuous(labels = scales::dollar_format(scale = 1e-6, suffix = \"M\", accuracy = 0.1)) +  # Format y-axis labels as dollars in millions\n    tidyquant::theme_tq() +  # Apply a theme from the tidyquant package\n    labs(\n        title = \"Total Sales for Each Model\",  # Set the title of the plot\n        x = \"Frame Material\", y = \"Revenue\"  # Set the axis labels\n    )\n\n#> Registered S3 method overwritten by 'quantmod':\n#>   method            from\n#>   as.zoo.data.frame zoo\n\n\n#> Warning: Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n#> Groups with fewer than two data points have been dropped.\n\n\n#> Warning in max(data$density): no non-missing arguments to max; returning -Inf\n\n\n#> Warning: Computation failed in `stat_ydensity()`\n#> Caused by error in `$<-.data.frame`:\n#> ! replacement has 1 row, data has 0\n\n\n\n\n\n\n\n\n#Data Preparation\n\nbike_features_tbl <- readRDS(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/bike_features_tbl.rds\")\nglimpse(bike_features_tbl)\n\n#> Rows: 231\n#> Columns: 67\n#> $ bike_id                     <dbl> 2875, 2873, 2874, 2876, 2877, 2225, 2091, …\n#> $ model                       <chr> \"Aeroad CF SL Disc 8.0 Di2\", \"Aeroad CF SL…\n#> $ model_year                  <dbl> 2020, 2020, 2020, 2020, 2020, 2019, 2019, …\n#> $ frame_material              <chr> \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"c…\n#> $ weight                      <dbl> 7.60, 7.27, 7.10, 7.73, 7.83, 6.80, 6.80, …\n#> $ price                       <dbl> 4579, 6919, 6429, 5069, 3609, 6139, 5359, …\n#> $ category_1                  <chr> \"Road\", \"Road\", \"Road\", \"Road\", \"Road\", \"R…\n#> $ category_2                  <chr> \"Race\", \"Race\", \"Race\", \"Race\", \"Race\", \"R…\n#> $ category_3                  <chr> \"Aeroad\", \"Aeroad\", \"Aeroad\", \"Aeroad\", \"A…\n#> $ gender                      <chr> \"unisex\", \"unisex\", \"unisex\", \"unisex\", \"u…\n#> $ url                         <chr> \"https://www.canyon.com/en-de/road-bikes/r…\n#> $ Frame                       <chr> \"Canyon Aeroad CF SL Disc\", \"Canyon Aeroad…\n#> $ Fork                        <chr> \"Canyon FK0041 CF SLX Disc\", \"Canyon FK004…\n#> $ `Rear Derailleur`           <chr> \"Shimano Ultegra Di2 R8050 SS\", \"SRAM RED …\n#> $ `Front Derailleur`          <chr> \"Shimano Ultegra Di2 R8050\", \"SRAM RED eTa…\n#> $ Cassette                    <chr> \"Shimano Ultegra R8000, 11-speed, 11-28T\",…\n#> $ Crank                       <chr> \"Shimano Ultegra R8000\", \"SRAM RED D1\", \"S…\n#> $ `Bottom bracket`            <chr> \"Shimano Pressfit BB72\", \"SRAM Pressfit RE…\n#> $ `Thru Axle`                 <chr> \"Canyon Thru Axle\", \"Canyon Thru Axle\", \"C…\n#> $ Cockpit                     <chr> \"Canyon H36 Aerocockpit CF\", \"Canyon H36 A…\n#> $ Saddle                      <chr> \"Selle Italia SLR\", \"Selle Italia SLR\", \"S…\n#> $ Seatpost                    <chr> \"Canyon S27 Aero VCLS CF\", \"Canyon S27 Aer…\n#> $ Pedals                      <chr> \"None included\", \"None included\", \"None in…\n#> $ `Derailleur hanger`         <chr> \"Shop Derailleur Hanger GP0211-01\", \"Shop …\n#> $ Battery                     <chr> \"\", \"SRAM eTap Powerpack\", \"\", \"SRAM eTap …\n#> $ Brake                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Shift Lever`               <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"Shimano Di2 Remot…\n#> $ Chain                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"Shimano CN-HG901 …\n#> $ Stem                        <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Canyon V13\", …\n#> $ Handlebar                   <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Canyon H16 Ae…\n#> $ Headset                     <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Motor                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Battery Charger`           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Flat Pedals`               <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Chainguard                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Aero Bar`                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake Lever / Master`      <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Wheel Tire System`         <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Suspension Fork`           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Disc Brake`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Grips                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Chainring                   <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Display                     <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Modeswitch                  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Rear Shock`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Light                       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Fender                      <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Bike Racks`                <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake 1`                   <chr> \"\", \"\", \"\", \"\", \"\", \"SRAM S-900 Direct Mou…\n#> $ `Brake 2`                   <chr> \"\", \"\", \"\", \"\", \"\", \"SRAM S-900 Direct Mou…\n#> $ `Shift-/ Brake Lever 1`     <chr> \"Shimano Ultegra Di2 R8070, 11-speed\", \"SR…\n#> $ `Shift-/ Brake Lever 2`     <chr> \"Shimano Ultegra Di2 R8070, 11-speed\", \"SR…\n#> $ `Wheel 1`                   <chr> \"DT Swiss ARC 1400 Dicut\", \"DT Swiss ARC 1…\n#> $ `Wheel 2`                   <chr> \"DT Swiss ARC 1400 Dicut\", \"DT Swiss ARC 1…\n#> $ `Tyre 1`                    <chr> \"Continental Grand Prix 5000 / Attack  23 …\n#> $ `Tyre 2`                    <chr> \"Continental Grand Prix 5000, 25 mm\", \"Con…\n#> $ `Handlebar Tape 1`          <chr> \"Canyon Ergospeed Gel\", \"Canyon Ergospeed …\n#> $ `Handlebar Tape 2`          <chr> \"Canyon bar-end plug\", \"Canyon bar-end plu…\n#> $ `Manuals and Accessories 1` <chr> \"Canyon tool case\", \"Canyon tool case\", \"C…\n#> $ `Manuals and Accessories 2` <chr> \"DT Swiss warranty & intended use manual\",…\n#> $ `Manuals and Accessories 3` <chr> \"Canyon starter box\", \"Canyon starter box\"…\n#> $ `Manuals and Accessories 4` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"BAG R…\n#> $ `Manuals and Accessories 5` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 6` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 7` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Manuals and Accessories 8` <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ `Brake Rotor`               <list> \"Shimano RT800\", \"SRAM Centerline X\", \"Sh…\n\nbike_features_tbl\n\n\n\n  \n\n\nbike_features_tbl <- bike_features_tbl %>% \n    select(model:url, `Rear Derailleur`, `Shift Lever`) %>% \n    mutate(\n      `shimano dura-ace`        = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano dura-ace \") %>% as.numeric(),\n      `shimano ultegra`         = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano ultegra \") %>% as.numeric(),\n      `shimano 105`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano 105 \") %>% as.numeric(),\n      `shimano tiagra`          = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano tiagra \") %>% as.numeric(),\n      `Shimano sora`            = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano sora\") %>% as.numeric(),\n      `shimano deore`           = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano deore(?! xt)\") %>% as.numeric(),\n      `shimano slx`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano slx\") %>% as.numeric(),\n      `shimano grx`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano grx\") %>% as.numeric(),\n      `Shimano xt`              = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano deore xt |shimano xt \") %>% as.numeric(),\n      `Shimano xtr`             = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano xtr\") %>% as.numeric(),\n      `Shimano saint`           = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"shimano saint\") %>% as.numeric(),\n      `SRAM red`                = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram red\") %>% as.numeric(),\n      `SRAM force`              = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram force\") %>% as.numeric(),\n      `SRAM rival`              = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram rival\") %>% as.numeric(),\n      `SRAM apex`               = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram apex\") %>% as.numeric(),\n      `SRAM xx1`                = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram xx1\") %>% as.numeric(),\n      `SRAM x01`                = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram x01|sram xo1\") %>% as.numeric(),\n      `SRAM gx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram gx\") %>% as.numeric(),\n      `SRAM nx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram nx\") %>% as.numeric(),\n      `SRAM sx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram sx\") %>% as.numeric(),\n      `SRAM sx`                 = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"sram sx\") %>% as.numeric(),\n      `Campagnolo potenza`      = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"campagnolo potenza\") %>% as.numeric(),\n      `Campagnolo super record` = `Rear Derailleur` %>% str_to_lower() %>% str_detect(\"campagnolo super record\") %>% as.numeric(),\n      `shimano nexus`           = `Shift Lever`     %>% str_to_lower() %>% str_detect(\"shimano nexus\") %>% as.numeric(),\n      `shimano alfine`          = `Shift Lever`     %>% str_to_lower() %>% str_detect(\"shimano alfine\") %>% as.numeric()\n    ) %>% \n  # Remove original columns  \n  select(-c(`Rear Derailleur`, `Shift Lever`)) %>% \n  # Set all NAs to 0\n  mutate_if(is.numeric, ~replace(., is.na(.), 0))\n\n#bike_features_tbl\n\n\n2 Let’s order and tidy the tibble a bit. We need the following data:\n\n# 2.0 TRAINING & TEST SETS ----\n\nbike_features_tbl <- bike_features_tbl %>% \n  \n  mutate(id = row_number()) %>% \n  \n  select(id, everything())\nbike_features_tbl\n\n\n\n  \n\n\n\n\n3 split data in test and train set (randomly)\n\n# Filter E-Road because it caused problems (just 1 element, and it could no be in training and test -> error bc not known)\nbike_features_tbl <- bike_features_tbl %>%\n  filter(category_2 != \"E-Road\")\n\nbike_features_tbl %>% distinct(category_2)\n\n\n\n  \n\n\nsum(bike_features_tbl$category_2 == \"E-Road\")\n\n#> [1] 0\n\n# run both following commands at the same time\nset.seed(seed = 1113)\n\nsplit_obj <- initial_split(bike_features_tbl, prop = 0.80, strata = \"category_2\")\n\n# Check if testing contains all category_2 values\nsplit_obj %>% training() %>% distinct(category_2)\n\n\n\n  \n\n\nsplit_obj %>% testing() %>% distinct(category_2)\n\n\n\n  \n\n\n# Assign training and test data\ntrain_tbl <- training(split_obj)\ntest_tbl  <- testing(split_obj)\n\n# We have to remove spaces and dashes from the column names\ntrain_tbl <- train_tbl %>% set_names(str_replace_all(names(train_tbl), \" |-\", \"_\"))\ntest_tbl  <- test_tbl  %>% set_names(str_replace_all(names(test_tbl),  \" |-\", \"_\"))\n\n\n4 Linear Regression Model and prediction (bad result due to not well choosen features)\n\nmodel_01_linear_lm_simple <- linear_reg(mode = \"regression\") %>%\n    set_engine(\"lm\") %>%\n    fit(price ~ category_2 + frame_material, data = train_tbl)\ntest_tbl\n\n\n\n  \n\n\nmodel_01_linear_lm_simple %>%\n    predict(new_data = test_tbl)%>%\n\n    bind_cols(test_tbl %>% select(price)) %>%\n  \n    yardstick::metrics(truth = price, estimate = .pred)\n\n\n\n  \n\n\n\n\n5 New Bike to predict price (use simpel model with bad prediction (since I had some issues with the engineered features)\n\n# 5.1 NEW MODEL ----\n\nnew_cross_country <- tibble(\n        model = \"Exceed AL SL new\",\n        category_2 = \"Cross-Country\",\n        frame_material = \"aluminium\",\n        shimano_dura_ace = 0,\n        shimano_ultegra = 0,\n        shimano_105 = 0,\n        shimano_tiagra = 0,\n        Shimano_sora = 0,\n        shimano_deore = 0,\n        shimano_slx = 0,\n        shimano_grx = 0,\n        Shimano_xt = 1,\n        Shimano_xtr = 0,\n        Shimano_saint = 0,\n        SRAM_red = 0,\n        SRAM_force = 0,\n        SRAM_rival = 0,\n        SRAM_apex = 0,\n        SRAM_xx1 = 0,\n        SRAM_x01 = 0,\n        SRAM_gx = 0,\n        SRAM_nx = 0,\n        SRAM_sx = 0,\n        Campagnolo_potenza = 0,\n        Campagnolo_super_record = 0,\n        shimano_nexus = 0,\n        shimano_alfine = 0\n) \n\nnew_cross_country\n\n\n\n  \n\n\npredict(model_01_linear_lm_simple,, new_data = new_cross_country)\n\n\n\n  \n\n\n\n\n6 engineered feature for better prediction\n\n# 3.2.1 Model ----\nmodel_02_linear_lm_complex <- linear_reg(\"regression\") %>%\n    set_engine(\"lm\") %>%\n    \n    # This is going to be different. Remove unnecessary columns.\n    fit(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender)))\n\n#model_02_linear_lm_complex %>% calc_metrics(new_data = test_tbl)\n\n#1 CHALLENGE WITH RECIPES PACKAGE:\n\n# define the model\nlm_model_spec <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  set_mode(\"regression\")\n\n#2\n\nrecipe_obj <- recipe(price ~ ., data = train_tbl) %>%\n  step_rm(id, url, model) %>%\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%\n  prep()\n\n# Apply preprocessing features to train and test data\ntrain_transformed_tbl <- bake(recipe_obj, new_data = train_tbl)\ntest_transformed_tbl  <- bake(recipe_obj, new_data = test_tbl)\n\n# Combine in workflow\nworkflow_obj <- workflow() %>%\n  add_recipe(recipe_obj) %>%\n  add_model(lm_model_spec) %>%\n  fit(data = train_tbl)\n\n# make predictions\npredictions <- predict(workflow_obj, new_data = test_tbl)\n\n#> Warning in predict.lm(object = object$fit, newdata = new_data, type =\n#> \"response\"): prediction from a rank-deficient fit may be misleading\n\n\n\n# Combine predictions with actual prices\npredictions_with_actual <- bind_cols(test_transformed_tbl %>% select(price), predictions)\n\n# Calculate evaluation metrics\nevaluation_metrics <- yardstick::metrics(predictions_with_actual, truth = price, estimate = .pred)\n\n# Print evaluation metrics\nprint(evaluation_metrics)\n\n#> # A tibble: 3 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard    1073.   \n#> 2 rsq     standard       0.523\n#> 3 mae     standard     771."
  },
  {
    "objectID": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html",
    "href": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "",
    "text": "#install.packages(\"h2o\")\nlibrary(h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n\n\n#> \n#> Attaching package: 'h2o'\n\n\n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n\n\n#> The following objects are masked from 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n\n# To launch H2O locally with default initialization arguments, use the following: \nh2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         2 hours 1 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.13 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)"
  },
  {
    "objectID": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#load-the-training-test-dataset",
    "href": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#load-the-training-test-dataset",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.1 1. Load the training & test dataset",
    "text": "1.1 1. Load the training & test dataset\n\n# Required Libraries\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ lubridate::day()   masks h2o::day()\n#> ✖ dplyr::filter()    masks stats::filter()\n#> ✖ lubridate::hour()  masks h2o::hour()\n#> ✖ dplyr::lag()       masks stats::lag()\n#> ✖ lubridate::month() masks h2o::month()\n#> ✖ lubridate::week()  masks h2o::week()\n#> ✖ lubridate::year()  masks h2o::year()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(recipes)\n\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n\nlibrary(rsample)\nlibrary(h2o)\n\n\n# Initialize H2O\nh2o_connection <- h2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         2 hours 1 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.13 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n\n# Read and Split Data\nproduct_backorders_tbl <- read_csv(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/product_backorders.csv\")\n\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#test print\n#product_backorders_tbl\nset_seed <- 1113\nsplit_obj <- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_data_tbl <- training(split_obj)\ntest_data_tbl <- testing(split_obj)\n\n# Data Preparation\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_data_tbl) %>%\n  step_zv(all_predictors()) %>%\n  prep()\n\ntrain_prepared_tbl <- bake(recipe_obj, new_data = train_data_tbl)\ntest_prepared_tbl <- bake(recipe_obj, new_data = test_data_tbl)\n#train_prepared_tbl\n#test_prepared_tbl"
  },
  {
    "objectID": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#specifiy-the-response-and-predictor-variables",
    "href": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#specifiy-the-response-and-predictor-variables",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.2 2.Specifiy the response and predictor variables",
    "text": "1.2 2.Specifiy the response and predictor variables\n\n# Divide the data into a training and a validation data frame\n# The seed is set for the sake of reproducibility\nsplit_h2o <- h2o.splitFrame(as.h2o(train_prepared_tbl), ratios = c(0.85), seed = 1234)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_prepared_tbl)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Define the response variable\ntarget_variable <- \"went_on_backorder\"\n\n# Define the predictor variables\nfeature_variables <- setdiff(names(train_h2o), target_variable)"
  },
  {
    "objectID": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#run-automl-specifying-the-stopping-criterion",
    "href": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#run-automl-specifying-the-stopping-criterion",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.3 3 run AutoML specifying the stopping criterion",
    "text": "1.3 3 run AutoML specifying the stopping criterion\n\n# Run automated machine learning\nautoml_model_h2o <- h2o.automl(\n  x = feature_variables,\n  y = target_variable,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs = 30,\n  nfolds = 5\n)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n#> 08:26:40.306: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 08:26:40.308: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n\n#train_h2o\n#valid_h2o\n#test_h2o\n# Check the type of the automl_model_h2o object\nmodel_type <- typeof(automl_model_h2o)\n\n#model_type"
  },
  {
    "objectID": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#view-the-leaderboard-5.save-the-leader-model-6.load-the-model",
    "href": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#view-the-leaderboard-5.save-the-leader-model-6.load-the-model",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.4 4. View the leaderboard 5.Save the leader model 6.Load the model",
    "text": "1.4 4. View the leaderboard 5.Save the leader model 6.Load the model\n\n# Get the names of slots in the automl_models_h2o object\nslots <- slotNames(automl_model_h2o)\n\n# Access the leaderboard from the automl_models_h2o object\nleaderboard <- automl_model_h2o@leaderboard\nleaderboard\n\n#>                                                  model_id       auc   logloss\n#> 1 StackedEnsemble_BestOfFamily_3_AutoML_12_20230615_82640 0.9518686 0.1748054\n#> 2    StackedEnsemble_AllModels_2_AutoML_12_20230615_82640 0.9512450 0.1751240\n#> 3 StackedEnsemble_BestOfFamily_2_AutoML_12_20230615_82640 0.9508860 0.1767061\n#> 4    StackedEnsemble_AllModels_1_AutoML_12_20230615_82640 0.9506600 0.1761617\n#> 5                          GBM_4_AutoML_12_20230615_82640 0.9495704 0.1782795\n#> 6                          GBM_3_AutoML_12_20230615_82640 0.9470881 0.1838058\n#>       aucpr mean_per_class_error      rmse        mse\n#> 1 0.7226038            0.1324578 0.2288391 0.05236731\n#> 2 0.7212276            0.1187951 0.2300424 0.05291952\n#> 3 0.7176618            0.1493571 0.2297406 0.05278074\n#> 4 0.7188289            0.1348982 0.2306037 0.05317805\n#> 5 0.7163029            0.1403840 0.2308283 0.05328171\n#> 6 0.7004171            0.1203357 0.2352896 0.05536118\n#> \n#> [14 rows x 7 columns]\n\n\n\n# Extract the name of a specific model from the leaderboard\nget_model_name <- function(h2o_leaderboard, n = 1, verbose = T) {\n  \n  model_name <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(n) %>%\n    pull(model_id)\n  \n  if (verbose) message(model_name)\n  \n  return(model_name)\n  \n}\n\n# Get the name of the 6th model in the leaderboard\nmodel_name <- automl_model_h2o@leaderboard %>% \n  get_model_name(1) %>% \n  h2o.getModel()\n\n#> StackedEnsemble_BestOfFamily_3_AutoML_12_20230615_82640\n\n# Save the specified model\n#h2o.getModel(\"StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\") %>% \n#h2o.saveModel(path = \"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/\")\n\n\n# Load a specific model\nloaded_model <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\")"
  },
  {
    "objectID": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#predicting-using-leader-model",
    "href": "content/01_journal/03_Challenge3_automated_machine_learning_with_h20_1.html#predicting-using-leader-model",
    "title": "Automated Machine Learning with H20 (I) & (II)",
    "section": "\n1.5 5.Predicting using Leader Model",
    "text": "1.5 5.Predicting using Leader Model\n\n# Generate predictions using the Stacked Ensemble model\npredictions <- h2o.predict(loaded_model, newdata = as.h2o(test_h2o))\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Check the type of the predictions object\npred_type <- typeof(predictions)\n\n# Convert predictions to a tibble\npredictions_tbl <- as_tibble(predictions)\nsaveRDS(predictions_tbl, \"/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/predictions_tbl.rds\")\nView(predictions_tbl)\n\nknitr::include_graphics(\"/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/went_back_prediction.png\")"
  },
  {
    "objectID": "content/01_journal/04_Challenge4_performance_measures.html",
    "href": "content/01_journal/04_Challenge4_performance_measures.html",
    "title": "Performance Meassures",
    "section": "",
    "text": "# Required Libraries\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(recipes)\n\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n\nlibrary(rsample)\nlibrary(h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n#> \n#> \n#> Attaching package: 'h2o'\n#> \n#> The following objects are masked from 'package:lubridate':\n#> \n#>     day, hour, month, week, year\n#> \n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n#> \n#> The following objects are masked from 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n\n# Initialize H2O\nh2o_connection <- h2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         2 hours 3 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.10 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n\n# Read and Split Data\nproduct_backorders_tbl <- read_csv(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/product_backorders.csv\")\n\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#test print\n#product_backorders_tbl\nset_seed <- 1205\nsplit_obj <- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_data_tbl <- training(split_obj)\ntest_data_tbl <- testing(split_obj)\n\n# Data Preparation\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_data_tbl) %>%\n  step_zv(all_predictors()) %>%\n  prep()\n\ntrain_prepared_tbl <- bake(recipe_obj, new_data = train_data_tbl)\ntest_prepared_tbl <- bake(recipe_obj, new_data = test_data_tbl)\n\n# Divide the data into a training and a validation data frame\n# The seed is set for the sake of reproducibility\nsplit_h2o <- h2o.splitFrame(as.h2o(train_prepared_tbl), ratios = c(0.85), seed = 1234)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_prepared_tbl)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Define the response variable\ntarget_variable <- \"went_on_backorder\"\n\n# Define the predictor variables\nfeature_variables <- setdiff(names(train_h2o), target_variable)\n\n# Run automated machine learning\nautoml_model_h2o <- h2o.automl(\n  x = feature_variables,\n  y = target_variable,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs = 30,\n  nfolds = 5\n)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n#> 08:28:29.910: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 08:28:29.912: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |==========================================================            |  84%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n\n# Check the type of the automl_model_h2o object\nmodel_type <- typeof(automl_model_h2o)\n\n\n1 1. Leaderboard visualization\n\n# Visualize the H2O leaderboard to help with model selection\ndata_transformed_tbl <- automl_model_h2o@leaderboard %>%\n  \n# Step 1: Get the leaderboard from the H2O AutoML model and convert   it to a tibble\n  as.tibble() %>%\n\n# Step 2: Exclude certain columns from the tibble\n  select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n  \n# Step 3: Extract the model type from the model ID and create a new   column\n  mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n  \n# Step 4: Select the top 15 models from the leaderboard\n  slice(1:15) %>% \n  \n# Step 5: Convert the rownames to a new column\n  rownames_to_column(var = \"rowname\") %>%\n  \n#Step 6: Reorder the factors in the model_id and model_type columns\n  mutate(\n    model_id   = as_factor(model_id) %>% reorder(auc),\n    model_type = as_factor(model_type)\n    \n# Step 7: Transform the tibble from wide to long format\n  ) %>% \n  pivot_longer(cols = -c(model_id, model_type, rowname), \n               names_to = \"key\", \n               values_to = \"value\", \n               names_transform = list(key = forcats::fct_inorder)\n  ) %>% \n  \n# Step 8: Modify the model_id column by combining it with the rowname and reverse the order\n  mutate(model_id = paste0(rowname, \". \", model_id) %>% as_factor() %>% fct_rev())\n\n#> Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#> ℹ Please use `as_tibble()` instead.\n#> ℹ The signature and semantics have changed, see `?as_tibble`.\n\ndata_transformed_tbl %>%\n  ggplot(aes(value, model_id, color = model_type)) +\n  geom_point(size = 3) +\n  geom_label(aes(label = round(value, 2), hjust = \"inward\")) +\n  \n  # Facet to break out logloss and auc\n  facet_wrap(~ key, scales = \"free_x\") +\n  labs(title = \"Leaderboard Metrics\",\n       subtitle = paste0(\"Ordered by: \", \"auc\"),\n       y = \"Model Postion, Model ID\", x = \"\") + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nplot_h2o_leaderboard <- function(h2o_leaderboard, order_by = c(\"auc\", \"logloss\"), \n                                 n_max = 20, size = 4, include_lbl = TRUE) {\n  \n  # Setup inputs\n  # adjust input so that all formats are working\n  order_by <- tolower(order_by[[1]])\n  \n  leaderboard_tbl <- h2o_leaderboard@leaderboard %>%\n    as.tibble() %>%\n    select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n    mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n    rownames_to_column(var = \"rowname\") %>%\n    mutate(model_id = paste0(rowname, \". \", model_id) %>% as_factor())\n  \n  # Transformation\n  if (order_by == \"auc\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(auc),\n        model_type = as_factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else if (order_by == \"logloss\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(logloss) %>% fct_rev(),\n        model_type = as_factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else {\n    # If nothing is supplied\n    stop(paste0(\"order_by = '\", order_by, \"' is not a permitted option.\"))\n  }\n  \n  # Visualization\n  g <- data_transformed_tbl %>%\n    ggplot(aes(value, model_id, color = model_type)) +\n    geom_point(size = size) +\n    facet_wrap(~ key, scales = \"free_x\") +\n    labs(title = \"Leaderboard Metrics\",\n         subtitle = paste0(\"Ordered by: \", toupper(order_by)),\n         y = \"Model Postion, Model ID\", x = \"\")\n  \n  if (include_lbl) g <- g + geom_label(aes(label = round(value, 2), \n                                           hjust = \"inward\"))\n  \n  return(g)\n  \n}\n\n#2 Tune a model with grid search\ndeeplearning_h2o <- h2o.loadModel(“C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046”)\n\n2 Take a look for the metrics on the training data set\n\n3 For my model the total error in the confusion matrix is ~15 %\ndeeplearning_h2o\n\n4 We want to see how it performs for the testing data frame\ntest_h2o\n\n5 Make sure to convert it to an h20 object\n\n6 Accuracy of the confusion matrix shows ~85 % accuracy\nh2o.performance(deeplearning_h2o, newdata = as.h2o(test_h2o))\ndeeplearning_grid_01 <- h2o.grid(\n# See help page for available algos algorithm = “deeplearning”,\n# I just use the same as the object #grid_id = “deeplearning_grid_01”,\n# The following is for ?h2o.deeplearning() # predictor and response variables y = target_variable, x = feature_variables,\n# training and validation frame and crossfold validation training_frame = train_h2o, validation_frame = valid_h2o, nfolds = 5,\n# Hyperparamters: Use deeplearning_h2o@allparameters to see all hyper_params = list( # Use some combinations (the first one was the original) hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)), epochs = c(10, 50, 100) ) )\ndeeplearning_grid_01\nh2o.getGrid(grid_id = “deeplearning_grid_01”, sort_by = “auc”, decreasing = TRUE)\ndeeplearning_grid_01_model_1 <- h2o.getModel(“deeplearning_grid_01_model_1”)\ndeeplearning_grid_01_model_1 %>% h2o.auc(train = T, valid = T, xval = T)\n\n7 We can tell the model is overfitting because of the huge difference between training AUC and the validation / cross validation AUC\n\n8 Run it on the test data\ndeeplearning_grid_01_model_1 %>% h2o.performance(newdata = as.h2o(test_h2o))\n\nstacked_ensemble_h2o <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\")\nGBM_h2o <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/GBM_1_AutoML_1_20230612_230009\")\n\nperformance_h2o_stacked <- h2o.performance(stacked_ensemble_h2o, newdata = as.h2o(test_h2o))\nperformance_h2o_gbm <- h2o.performance(GBM_h2o, newdata = as.h2o(test_h2o))\n\ntypeof(performance_h2o_stacked)\n\n#> [1] \"S4\"\n\nperformance_h2o_stacked %>% slotNames()\n\n#> [1] \"algorithm\" \"on_train\"  \"on_valid\"  \"on_xval\"   \"metrics\"\n\n# We are focusing on the slot metrics. This slot contains all possible metrics\nperformance_h2o_stacked@metrics\n\n#> $model\n#> $model$`__meta`\n#> $model$`__meta`$schema_version\n#> [1] 3\n#> \n#> $model$`__meta`$schema_name\n#> [1] \"ModelKeyV3\"\n#> \n#> $model$`__meta`$schema_type\n#> [1] \"Key<Model>\"\n#> \n#> \n#> $model$name\n#> [1] \"StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\"\n#> \n#> $model$type\n#> [1] \"Key<Model>\"\n#> \n#> $model$URL\n#> [1] \"/3/Models/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\"\n#> \n#> \n#> $model_checksum\n#> [1] \"-8682890534361748960\"\n#> \n#> $frame\n#> $frame$name\n#> [1] \"test_h2o_sid_a5e5_144\"\n#> \n#> \n#> $frame_checksum\n#> [1] \"1414251131096891176\"\n#> \n#> $description\n#> NULL\n#> \n#> $scoring_time\n#> [1] 1.686811e+12\n#> \n#> $predictions\n#> NULL\n#> \n#> $MSE\n#> [1] 0.03713402\n#> \n#> $RMSE\n#> [1] 0.1927019\n#> \n#> $nobs\n#> [1] 2858\n#> \n#> $custom_metric_name\n#> NULL\n#> \n#> $custom_metric_value\n#> [1] 0\n#> \n#> $r2\n#> [1] 0.6457076\n#> \n#> $logloss\n#> [1] 0.1278478\n#> \n#> $AUC\n#> [1] 0.9753732\n#> \n#> $pr_auc\n#> [1] 0.859624\n#> \n#> $Gini\n#> [1] 0.9507464\n#> \n#> $mean_per_class_error\n#> [1] 0.1157676\n#> \n#> $domain\n#> [1] \"No\"  \"Yes\"\n#> \n#> $cm\n#> $cm$`__meta`\n#> $cm$`__meta`$schema_version\n#> [1] 3\n#> \n#> $cm$`__meta`$schema_name\n#> [1] \"ConfusionMatrixV3\"\n#> \n#> $cm$`__meta`$schema_type\n#> [1] \"ConfusionMatrix\"\n#> \n#> \n#> $cm$table\n#> Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n#>          No Yes  Error          Rate\n#> No     2446  72 0.0286 =  72 / 2,518\n#> Yes      69 271 0.2029 =    69 / 340\n#> Totals 2515 343 0.0493 = 141 / 2,858\n#> \n#> \n#> $thresholds_and_metric_scores\n#> Metrics for Thresholds: Binomial metrics as a function of classification thresholds\n#>   threshold       f1       f2 f0point5 accuracy precision   recall specificity\n#> 1  0.997446 0.017493 0.011005 0.042614 0.882085  1.000000 0.008824    1.000000\n#> 2  0.994694 0.034682 0.021962 0.082418 0.883135  1.000000 0.017647    1.000000\n#> 3  0.988375 0.045977 0.029240 0.107527 0.883835  1.000000 0.023529    1.000000\n#> 4  0.985202 0.051576 0.032871 0.119681 0.884185  1.000000 0.026471    1.000000\n#> 5  0.979324 0.062678 0.040117 0.143229 0.884885  1.000000 0.032353    1.000000\n#>   absolute_mcc min_per_class_accuracy mean_per_class_accuracy  tns fns fps tps\n#> 1     0.088216               0.008824                0.504412 2518 337   0   3\n#> 2     0.124821               0.017647                0.508824 2518 334   0   6\n#> 3     0.144182               0.023529                0.511765 2518 332   0   8\n#> 4     0.152955               0.026471                0.513235 2518 331   0   9\n#> 5     0.169157               0.032353                0.516176 2518 329   0  11\n#>        tnr      fnr      fpr      tpr idx\n#> 1 1.000000 0.991176 0.000000 0.008824   0\n#> 2 1.000000 0.982353 0.000000 0.017647   1\n#> 3 1.000000 0.976471 0.000000 0.023529   2\n#> 4 1.000000 0.973529 0.000000 0.026471   3\n#> 5 1.000000 0.967647 0.000000 0.032353   4\n#> \n#> ---\n#>     threshold       f1       f2 f0point5 accuracy precision   recall\n#> 395  0.001131 0.238429 0.439050 0.163650 0.240028  0.135350 1.000000\n#> 396  0.000866 0.233436 0.432240 0.159895 0.218684  0.132141 1.000000\n#> 397  0.000628 0.226365 0.422465 0.154602 0.186844  0.127628 1.000000\n#> 398  0.000398 0.220279 0.413927 0.150071 0.157803  0.123771 1.000000\n#> 399  0.000182 0.212766 0.403226 0.144509 0.119664  0.119048 1.000000\n#> 400  0.000037 0.212633 0.403035 0.144410 0.118964  0.118964 1.000000\n#>     specificity absolute_mcc min_per_class_accuracy mean_per_class_accuracy tns\n#> 395    0.137411     0.136377               0.137411                0.568705 346\n#> 396    0.113185     0.122297               0.113185                0.556593 285\n#> 397    0.077045     0.099162               0.077045                0.538523 194\n#> 398    0.044083     0.073866               0.044083                0.522041 111\n#> 399    0.000794     0.009724               0.000794                0.500397   2\n#> 400    0.000000     0.000000               0.000000                0.500000   0\n#>     fns  fps tps      tnr      fnr      fpr      tpr idx\n#> 395   0 2172 340 0.137411 0.000000 0.862589 1.000000 394\n#> 396   0 2233 340 0.113185 0.000000 0.886815 1.000000 395\n#> 397   0 2324 340 0.077045 0.000000 0.922955 1.000000 396\n#> 398   0 2407 340 0.044083 0.000000 0.955917 1.000000 397\n#> 399   0 2516 340 0.000794 0.000000 0.999206 1.000000 398\n#> 400   0 2518 340 0.000000 0.000000 1.000000 1.000000 399\n#> \n#> $max_criteria_and_metric_scores\n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.377706    0.793558 181\n#> 2                       max f2  0.143508    0.835987 261\n#> 3                 max f0point5  0.538587    0.831006 141\n#> 4                 max accuracy  0.478325    0.953464 156\n#> 5                max precision  0.997446    1.000000   0\n#> 6                   max recall  0.005501    1.000000 382\n#> 7              max specificity  0.997446    1.000000   0\n#> 8             max absolute_mcc  0.478325    0.767372 156\n#> 9   max min_per_class_accuracy  0.148315    0.918586 259\n#> 10 max mean_per_class_accuracy  0.138768    0.921815 264\n#> 11                     max tns  0.997446 2518.000000   0\n#> 12                     max fns  0.997446  337.000000   0\n#> 13                     max fps  0.000037 2518.000000 399\n#> 14                     max tps  0.005501  340.000000 382\n#> 15                     max tnr  0.997446    1.000000   0\n#> 16                     max fnr  0.997446    0.991176   0\n#> 17                     max fpr  0.000037    1.000000 399\n#> 18                     max tpr  0.005501    1.000000 382\n#> \n#> $gains_lift_table\n#> Gains/Lift Table: Avg response rate: 11.90 %, avg score: 11.78 %\n#>    group cumulative_data_fraction lower_threshold     lift cumulative_lift\n#> 1      1               0.01014696        0.954918 8.405882        8.405882\n#> 2      2               0.02029391        0.918065 7.536308        7.971095\n#> 3      3               0.03009097        0.878561 7.805462        7.917168\n#> 4      4               0.04023793        0.842280 7.826166        7.894220\n#> 5      5               0.05003499        0.803527 7.505252        7.818058\n#> 6      6               0.10006998        0.516111 6.583628        7.200843\n#> 7      7               0.15010497        0.242589 2.880337        5.760675\n#> 8      8               0.20013996        0.115529 1.469560        4.687896\n#> 9      9               0.30020994        0.038808 0.470259        3.282017\n#> 10    10               0.39993002        0.019265 0.088483        2.485729\n#> 11    11               0.50000000        0.012350 0.029391        1.994118\n#> 12    12               0.60006998        0.007684 0.000000        1.661571\n#> 13    13               0.69979006        0.004287 0.029494        1.429000\n#> 14    14               0.79986004        0.002025 0.000000        1.250219\n#> 15    15               0.89993002        0.000762 0.000000        1.111198\n#> 16    16               1.00000000        0.000000 0.000000        1.000000\n#>    response_rate    score cumulative_response_rate cumulative_score\n#> 1       1.000000 0.977545                 1.000000         0.977545\n#> 2       0.896552 0.933025                 0.948276         0.955285\n#> 3       0.928571 0.895426                 0.941860         0.935796\n#> 4       0.931034 0.859738                 0.939130         0.916616\n#> 5       0.892857 0.823272                 0.930070         0.898339\n#> 6       0.783217 0.668659                 0.856643         0.783499\n#> 7       0.342657 0.357524                 0.685315         0.641507\n#> 8       0.174825 0.168206                 0.557692         0.523182\n#> 9       0.055944 0.067783                 0.390443         0.371382\n#> 10      0.010526 0.027251                 0.295713         0.285575\n#> 11      0.003497 0.015539                 0.237229         0.231530\n#> 12      0.000000 0.009906                 0.197668         0.194571\n#> 13      0.003509 0.006046                 0.170000         0.167707\n#> 14      0.000000 0.002995                 0.148731         0.147100\n#> 15      0.000000 0.001364                 0.132193         0.130894\n#> 16      0.000000 0.000380                 0.118964         0.117834\n#>    capture_rate cumulative_capture_rate        gain cumulative_gain\n#> 1      0.085294                0.085294  740.588235      740.588235\n#> 2      0.076471                0.161765  653.630832      697.109533\n#> 3      0.076471                0.238235  680.546218      691.716826\n#> 4      0.079412                0.317647  682.616633      689.421995\n#> 5      0.073529                0.391176  650.525210      681.805841\n#> 6      0.329412                0.720588  558.362814      620.084327\n#> 7      0.144118                0.864706  188.033731      476.067462\n#> 8      0.073529                0.938235   46.955985      368.789593\n#> 9      0.047059                0.985294  -52.974085      228.201700\n#> 10     0.008824                0.994118  -91.151703      148.572899\n#> 11     0.002941                0.997059  -97.060880       99.411765\n#> 12     0.000000                0.997059 -100.000000       66.157091\n#> 13     0.002941                1.000000  -97.050568       42.900000\n#> 14     0.000000                1.000000 -100.000000       25.021872\n#> 15     0.000000                1.000000 -100.000000       11.119751\n#> 16     0.000000                1.000000 -100.000000        0.000000\n#>    kolmogorov_smirnov\n#> 1            0.085294\n#> 2            0.160573\n#> 3            0.236250\n#> 4            0.314867\n#> 5            0.387205\n#> 6            0.704305\n#> 7            0.811092\n#> 8            0.837759\n#> 9            0.777590\n#> 10           0.674419\n#> 11           0.564176\n#> 12           0.450593\n#> 13           0.340747\n#> 14           0.227164\n#> 15           0.113582\n#> 16           0.000000\n#> \n#> $residual_deviance\n#> [1] 730.7778\n#> \n#> $null_deviance\n#> [1] 2085.574\n#> \n#> $AIC\n#> [1] 738.7778\n#> \n#> $null_degrees_of_freedom\n#> [1] 2857\n#> \n#> $residual_degrees_of_freedom\n#> [1] 2854\n\n# Classifier Summary Metrics\n\nh2o.auc(performance_h2o_stacked, train = TRUE, valid = TRUE, xval = TRUE)\n\n#> [1] 0.9753732\n\n# Caution: \"train, \"val\", and \"xval\" arguments only work for models (not performance objects)\nh2o.auc(stacked_ensemble_h2o, train = TRUE, valid = TRUE, xval = TRUE)\n\n#>     train     valid      xval \n#> 0.9898581 0.9540598 0.9527319\n\nh2o.giniCoef(performance_h2o_stacked)\n\n#> [1] 0.9507464\n\nh2o.logloss(performance_h2o_stacked)\n\n#> [1] 0.1278478\n\nh2o.confusionMatrix(stacked_ensemble_h2o)\n\n\n\n  \n\n\n# Result for the holdout set\nh2o.confusionMatrix(performance_h2o_stacked)\n\n\n\n  \n\n\n# Precision vs Recall Plot\n\n# This is on the test set\nperformance_tbl_stacked <- performance_h2o_stacked %>%\n  h2o.metric() %>%\n  as.tibble() \n\nperformance_tbl_stacked %>%\n  glimpse()\n\n#> Rows: 400\n#> Columns: 20\n#> $ threshold               <dbl> 0.9974459, 0.9946936, 0.9883745, 0.9852018, 0.…\n#> $ f1                      <dbl> 0.01749271, 0.03468208, 0.04597701, 0.05157593…\n#> $ f2                      <dbl> 0.01100514, 0.02196193, 0.02923977, 0.03287071…\n#> $ f0point5                <dbl> 0.04261364, 0.08241758, 0.10752688, 0.11968085…\n#> $ accuracy                <dbl> 0.8820854, 0.8831351, 0.8838348, 0.8841847, 0.…\n#> $ precision               <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ recall                  <dbl> 0.008823529, 0.017647059, 0.023529412, 0.02647…\n#> $ specificity             <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ absolute_mcc            <dbl> 0.08821572, 0.12482146, 0.14418197, 0.15295491…\n#> $ min_per_class_accuracy  <dbl> 0.008823529, 0.017647059, 0.023529412, 0.02647…\n#> $ mean_per_class_accuracy <dbl> 0.5044118, 0.5088235, 0.5117647, 0.5132353, 0.…\n#> $ tns                     <dbl> 2518, 2518, 2518, 2518, 2518, 2518, 2518, 2518…\n#> $ fns                     <dbl> 337, 334, 332, 331, 329, 327, 325, 320, 316, 3…\n#> $ fps                     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ tps                     <dbl> 3, 6, 8, 9, 11, 13, 15, 20, 24, 25, 26, 28, 29…\n#> $ tnr                     <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ fnr                     <dbl> 0.9911765, 0.9823529, 0.9764706, 0.9735294, 0.…\n#> $ fpr                     <dbl> 0.0000000000, 0.0000000000, 0.0000000000, 0.00…\n#> $ tpr                     <dbl> 0.008823529, 0.017647059, 0.023529412, 0.02647…\n#> $ idx                     <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, …\n\ntheme_new <- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"black\", fill = NA, linewidth = 0.5),\n  panel.grid.major = element_line(color = \"grey\", size = 0.333)\n) \n\n#> Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n#> ℹ Please use the `linewidth` argument instead.\n\nperformance_tbl_stacked %>%\n  filter(f1 == max(f1))\n\n\n\n  \n\n\nperformance_tbl_stacked %>%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"blue\", size = 1) +\n  geom_line(aes(y = recall), color = \"red\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o_stacked, \"f1\")) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n9 ROC Plot\n\npath <- \"Challeng3_automated_machine_learning_h2O/StackedEnsemble_AllModels_1_AutoML_1_20230610_174902\"\n\nload_model_performance_metrics <- function(path, test_h2o) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_h2o)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc)\n  \n}\n\nmodel_metrics_tbl <- fs::dir_info(path = \"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/\") %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_h2o)) %>%\n  unnest(cols = metrics)\n\nmodel_metrics_tbl %>%\n  mutate(\n    # Extract the model names\n    path = str_extract(path, \"(?<=/)[^/]+$\") %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(fpr, tpr, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  \n  # just for demonstration purposes\n  geom_abline(color = \"red\", linetype = \"dotted\") +\n  \n  theme_new +\n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"ROC Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n\n\n\n\n\n\n\n\n10 Precision vs Recall plot\n\n# Precision vs Recall\n\nload_model_performance_metrics <- function(path, test_tbl) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc, precision, recall)\n  \n}\n\nmodel_metrics_tbl <- fs::dir_info(path = \"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/\") %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_h2o)) %>%\n  unnest(cols = metrics)\n\nmodel_metrics_tbl %>%\n  mutate(\n    path = str_extract(path, \"(?<=/)[^/]+$\") %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(recall, precision, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  theme_new + \n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"Precision vs Recall Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n\n\n\n\n\n\n\n\n11 Gain Plot\n\n # Gain & Lift\npredictions_tbl <- readRDS(\"/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/predictions_tbl.rds\")\nranked_predictions_tbl <- predictions_tbl %>%\n  bind_cols(as.data.frame(test_h2o)\n) %>%\n  select(predict:No, went_on_backorder) %>%\n  # Sorting from highest to lowest class probability\n  arrange(desc(No))\n\nranked_predictions_tbl %>%\n  mutate(ntile = ntile(No, n = 10)) %>%\n  group_by(ntile) %>%\n  summarise(\n    cases = n(),\n    responses = sum(went_on_backorder == \"No\")\n  ) %>%\n  arrange(desc(ntile))\n\n\n\n  \n\n\ncalculated_gain_lift_tbl <- ranked_predictions_tbl %>%\n  mutate(ntile = ntile(No, n = 10)) %>%\n  group_by(ntile) %>%\n  summarise(\n    cases = n(),\n    responses = sum(went_on_backorder == \"No\")\n  ) %>%\n  arrange(desc(ntile)) %>%\n  \n  # Add group numbers (opposite of ntile)\n  mutate(group = row_number()) %>%\n  select(group, cases, responses) %>%\n  \n  # Calculations\n  mutate(\n    cumulative_responses = cumsum(responses),\n    pct_responses        = responses / sum(responses),\n    gain                 = cumsum(pct_responses),\n    cumulative_pct_cases = cumsum(cases) / sum(cases),\n    lift                 = gain / cumulative_pct_cases,\n    gain_baseline        = cumulative_pct_cases,\n    lift_baseline        = gain_baseline / cumulative_pct_cases\n  )\n\ncalculated_gain_lift_tbl \n\n\n\n  \n\n\ngain_lift_tbl <- performance_h2o_stacked %>%\n  h2o.gainsLift() %>%\n  as.tibble()\n\n## Gain Chart\n\ngain_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n\n\n\n\n\n\n\n\n12 Lift Plot\n\n## Lift Plot\n\nlift_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"capture\")) %>%\n  mutate(baseline = 1) %>%\n  rename(lift = cumulative_lift) %>%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Lift Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Lift\"\n  ) +\n  theme_new\n\n\n\n\n\n\n\n\n13 Cowplot Dashboard\n\n# 5. Performance Visualization ----  \nlibrary(cowplot)\n\n#> \n#> Attaching package: 'cowplot'\n\n\n#> The following object is masked from 'package:lubridate':\n#> \n#>     stamp\n\nlibrary(glue)\n\n\n# set values to test the function while building it\nh2o_leaderboard <- automl_model_h2o@leaderboard\nnewdata <- test_h2o\norder_by <- \"auc\"\nmax_models <- 4\nsize <- 1\n\nplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n  \n  # Inputs\n  \n  leaderboard_tbl <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(1:max_models)\n  \n  newdata_tbl <- newdata %>%\n    as_tibble()\n  \n  # Selecting the first, if nothing is provided\n  order_by      <- tolower(order_by[[1]]) \n  \n  # Convert string stored in a variable to column name (symbol)\n  order_by_expr <- rlang::sym(order_by)\n  \n  # Turn of the progress bars ( opposite h2o.show_progress())\n  h2o.no_progress()\n  \n  # 1. Model metrics\n  \n  get_model_performance_metrics <- function(model_id, test_h2o) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_h2o))\n    \n    perf_h2o %>%\n      h2o.metric() %>%\n      as.tibble() %>%\n      select(threshold, tpr, fpr, precision, recall)\n    \n  }\n  \n  model_metrics_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        # programmatically reorder factors depending on order_by\n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    )\n  \n  \n  # 1A. ROC Plot\n  \n  p1 <- model_metrics_tbl %>%\n    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n    theme(legend.direction = \"vertical\") \n  \n  \n  # 1B. Precision vs Recall\n  \n  p2 <- model_metrics_tbl %>%\n    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n    theme(legend.position = \"none\") \n  \n  \n  # 2. Gain / Lift\n  \n  get_gain_lift <- function(model_id, test_h2o) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_h2o)) \n    \n    perf_h2o %>%\n      h2o.gainsLift() %>%\n      as.tibble() %>%\n      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n    \n  }\n  \n  gain_lift_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc  = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    ) %>%\n    rename(\n      gain = cumulative_capture_rate,\n      lift = cumulative_lift\n    ) \n  \n  # 2A. Gain Plot\n  \n  p3 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, gain, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size,) +\n    geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Gain\",\n         x = \"Cumulative Data Fraction\", y = \"Gain\") +\n    theme(legend.position = \"none\")\n  \n  # 2B. Lift Plot\n  \n  p4 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, lift, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Lift\",\n         x = \"Cumulative Data Fraction\", y = \"Lift\") +\n    theme(legend.position = \"none\") \n  \n  \n  # Combine using cowplot\n  \n  # cowplot::get_legend extracts a legend from a ggplot object\n  p_legend <- get_legend(p1)\n  # Remove legend from p1\n  p1 <- p1 + theme(legend.position = \"none\")\n  \n  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n  p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n  \n  # cowplot::ggdraw() sets up a drawing layer\n  p_title <- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#2C3E50\")\n  \n  p_subtitle <- ggdraw() + \n    draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n               color = \"#2C3E50\")\n  \n  # Combine everything\n  ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n                   \n                   # Adjust the relative spacing, so that the legends always fits\n                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n  \n  h2o.show_progress()\n  \n  return(ret)\n  \n}\n\nautoml_model_h2o@leaderboard %>%\n  plot_h2o_performance(newdata = test_h2o, order_by = \"logloss\", \n                       size = 0.5, max_models = 4)"
  },
  {
    "objectID": "content/01_journal/05_Challenge5_Explaining_Black-Box_Models_With_LIME.html",
    "href": "content/01_journal/05_Challenge5_Explaining_Black-Box_Models_With_LIME.html",
    "title": "05_Explaining_Black-Box_Models_With_LIME",
    "section": "",
    "text": "TESTTEST # Load Libraries\n\nlibrary(rsample)\nlibrary(h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n\n\n#> \n#> Attaching package: 'h2o'\n\n\n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n\n\n#> The following objects are masked from 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n\nlibrary(recipes)\n\n#> Loading required package: dplyr\n\n\n#> \n#> Attaching package: 'dplyr'\n\n\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n\n\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\n\n#> \n#> Attaching package: 'recipes'\n\n\n#> The following object is masked from 'package:stats':\n#> \n#>     step\n\nlibrary(readxl)\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ forcats   1.0.0     ✔ readr     2.1.4\n#> ✔ ggplot2   3.4.2     ✔ stringr   1.5.0\n#> ✔ lubridate 1.9.2     ✔ tibble    3.2.1\n#> ✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ lubridate::day()   masks h2o::day()\n#> ✖ dplyr::filter()    masks stats::filter()\n#> ✖ stringr::fixed()   masks recipes::fixed()\n#> ✖ lubridate::hour()  masks h2o::hour()\n#> ✖ dplyr::lag()       masks stats::lag()\n#> ✖ lubridate::month() masks h2o::month()\n#> ✖ lubridate::week()  masks h2o::week()\n#> ✖ lubridate::year()  masks h2o::year()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(tidyquant)\n\n#> Loading required package: PerformanceAnalytics\n#> Loading required package: xts\n#> Loading required package: zoo\n#> \n#> Attaching package: 'zoo'\n#> \n#> The following objects are masked from 'package:base':\n#> \n#>     as.Date, as.Date.numeric\n#> \n#> \n#> ######################### Warning from 'xts' package ##########################\n#> #                                                                             #\n#> # The dplyr lag() function breaks how base R's lag() function is supposed to  #\n#> # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n#> # source() into this session won't work correctly.                            #\n#> #                                                                             #\n#> # Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n#> # conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n#> # dplyr from breaking base R's lag() function.                                #\n#> #                                                                             #\n#> # Code in packages is not affected. It's protected by R's namespace mechanism #\n#> # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#> #                                                                             #\n#> ###############################################################################\n#> \n#> Attaching package: 'xts'\n#> \n#> The following objects are masked from 'package:dplyr':\n#> \n#>     first, last\n#> \n#> \n#> Attaching package: 'PerformanceAnalytics'\n#> \n#> The following object is masked from 'package:graphics':\n#> \n#>     legend\n#> \n#> Loading required package: quantmod\n#> Loading required package: TTR\n#> Registered S3 method overwritten by 'quantmod':\n#>   method            from\n#>   as.zoo.data.frame zoo\n\nlibrary(lime)\n\n#> \n#> Attaching package: 'lime'\n#> \n#> The following object is masked from 'package:dplyr':\n#> \n#>     explain\n\nlibrary(ggplot2)\n\n\n1 Load Data\nemployee_attrition_tbl <- read_csv(“C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.txt”) definitions_raw_tbl <- read_excel(“C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/data_definitions.xlsx”, sheet = 1, col_names = FALSE)\n\n2 Processing Pipeline\nsource(“C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/data_processing_pipeline.R”)\nemployee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n\n3 Split into test and train\nset.seed(seed = 1113) split_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n4 Assign training and test data\ntrain_readable_tbl <- training(split_obj) test_readable_tbl <- testing(split_obj)\n\n5 ML Preprocessing Recipe\nrecipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>% step_zv(all_predictors()) %>% step_mutate_at(c(“JobLevel”, “StockOptionLevel”), fn = as.factor) %>% prep()\nrecipe_obj\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl) test_tbl <- bake(recipe_obj, new_data = test_readable_tbl)\n\n6 2. Models —-\nh2o.init()\nautoml_leader <- h2o.loadModel(“C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046”) automl_leader\n\n7 3. LIME —-\n\n8 3.1 Making Predictions —-\npredictions_tbl <- automl_leader %>% h2o.predict(newdata = as.h2o(test_tbl)) %>% as.tibble() %>% bind_cols( test_tbl %>% select(Attrition, EmployeeNumber) )\npredictions_tbl\ntest_tbl %>% slice(1) %>% glimpse()\n\n9 3.2 Single Explanation —-\nexplainer <- train_tbl %>% select(-Attrition) %>% lime( model = automl_leader, bin_continuous = TRUE, n_bins = 4, quantile_bins = TRUE )\nexplainer\nexplanation <- test_tbl %>% slice(1) %>% select(-Attrition) %>% lime::explain(\n# Pass our explainer object\nexplainer = explainer,\n# Because it is a binary classification model: 1\nn_labels   = 1,\n# number of features to be returned\nn_features = 8,\n# number of localized linear models\nn_permutations = 5000,\n# Let's start with 1\nkernel_width   = 1\n)\nexplanation\nexplanation %>% as.tibble() %>% select(feature:prediction)"
  }
]
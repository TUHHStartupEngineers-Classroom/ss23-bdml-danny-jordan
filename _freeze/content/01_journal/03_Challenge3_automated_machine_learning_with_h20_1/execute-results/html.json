{
  "hash": "a84125fee4a56586e10110fca4c5ea7d",
  "result": {
    "markdown": "---\ntitle: \"Automated Machine Learning with H20 (I) & (II)\"\nauthor: \"Danny Jordan\"\n---\n\n::: {.cell hash='03_Challenge3_automated_machine_learning_with_h20_1_cache/html/unnamed-chunk-1_ad7631ac81102292c4292d43acd9fd66'}\n\n```{.r .cell-code}\n#install.packages(\"h2o\")\nlibrary(h2o)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'h2o'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following objects are masked from 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n```\n:::\n\n```{.r .cell-code}\n# To launch H2O locally with default initialization arguments, use the following: \nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         2 hours 1 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.13 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n```\n:::\n:::\n\n\n\n\n# Challenge 3 Automated Machine Learning with H2O (I)\n\n1. Compensation Features-\nWhat can you deduce about the interaction between Monthly Income and Attrition? \nc. Those that are leaving have a lower Monthly Income\n\n2. Compensation Features-\nWhat can you deduce about the interaction between Percent Salary Hike and Attrition?\nc. Those that are leaving have lower Percent Salary Hike\n\n3. Compensation Features-\nWhat can you deduce about the interaction between Stock Option Level and Attrition?\nb. Those that are staying have a higher stock option level\n\n4. Survey Results-\nWhat can you deduce about the interaction between Environment Satisfaction and Attrition?\nA higher proportion of those leaving have a low environment satisfaction level\n\n5. Survey Results\nWhat can you deduce about the interaction between Work Life Balance and Attrition\nb. Those that are staying have a higher density of 2's and 3's\n\n6. Performance Data-\nWhat Can you deduce about the interaction between Job Involvement and Attrition?\na. Those that are leaving have a lower density of 3's and 4's\n\n7. Work-Life Features-\nWhat can you deduce about the interaction between Over Time and Attrition?\nb. The proportion of those staying that are working Over Time are high compared to those that are not staying\n\n8. Training and Education-\nWhat can you deduce about the interaction between Training Times Last Year and Attrition\nb. People that leave tend to have less annual trainings\n\n9. Time-Based Features-\nWhat can you deduce about the interaction between Years At Company and Attrition\nb. People that leave tend to have less working years at the company\n\n10. Time-Based Features-\nWhat can you deduce about the interaction between Years Since Last Promotion and Attrition?\na. Those that are leaving have more years since last promotion than those that are staying\n\n##  1. Load the training & test dataset\n\n::: {.cell hash='03_Challenge3_automated_machine_learning_with_h20_1_cache/html/unnamed-chunk-2_8219949ce854b5118fcfa757d9c84534'}\n\n```{.r .cell-code}\n# Required Libraries\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ lubridate::day()   masks h2o::day()\n#> ✖ dplyr::filter()    masks stats::filter()\n#> ✖ lubridate::hour()  masks h2o::hour()\n#> ✖ dplyr::lag()       masks stats::lag()\n#> ✖ lubridate::month() masks h2o::month()\n#> ✖ lubridate::week()  masks h2o::week()\n#> ✖ lubridate::year()  masks h2o::year()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n```\n:::\n\n```{.r .cell-code}\nlibrary(rsample)\nlibrary(h2o)\n\n\n# Initialize H2O\nh2o_connection <- h2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         2 hours 1 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.13 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n```\n:::\n\n```{.r .cell-code}\n# Read and Split Data\nproduct_backorders_tbl <- read_csv(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n#test print\n#product_backorders_tbl\nset_seed <- 1113\nsplit_obj <- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_data_tbl <- training(split_obj)\ntest_data_tbl <- testing(split_obj)\n\n# Data Preparation\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_data_tbl) %>%\n  step_zv(all_predictors()) %>%\n  prep()\n\ntrain_prepared_tbl <- bake(recipe_obj, new_data = train_data_tbl)\ntest_prepared_tbl <- bake(recipe_obj, new_data = test_data_tbl)\n#train_prepared_tbl\n#test_prepared_tbl\n```\n:::\n\n\n##  2.Specifiy the response and predictor variables\n\n\n::: {.cell hash='03_Challenge3_automated_machine_learning_with_h20_1_cache/html/unnamed-chunk-3_53aa413450fa1dd742e7d7faf1041bca'}\n\n```{.r .cell-code}\n# Divide the data into a training and a validation data frame\n# The seed is set for the sake of reproducibility\nsplit_h2o <- h2o.splitFrame(as.h2o(train_prepared_tbl), ratios = c(0.85), seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_prepared_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Define the response variable\ntarget_variable <- \"went_on_backorder\"\n\n# Define the predictor variables\nfeature_variables <- setdiff(names(train_h2o), target_variable)\n```\n:::\n\n\n\n## 3 run AutoML specifying the stopping criterion\n\n::: {.cell hash='03_Challenge3_automated_machine_learning_with_h20_1_cache/html/unnamed-chunk-4_f8321ccac5c39c513ebf42c2d0516dab'}\n\n```{.r .cell-code}\n# Run automated machine learning\nautoml_model_h2o <- h2o.automl(\n  x = feature_variables,\n  y = target_variable,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs = 30,\n  nfolds = 5\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n#> 08:26:40.306: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 08:26:40.308: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n#train_h2o\n#valid_h2o\n#test_h2o\n# Check the type of the automl_model_h2o object\nmodel_type <- typeof(automl_model_h2o)\n\n#model_type\n```\n:::\n\n\n\n## 4. View the leaderboard 5.Save the leader model 6.Load the model\n\n\n\n::: {.cell hash='03_Challenge3_automated_machine_learning_with_h20_1_cache/html/unnamed-chunk-5_edbb14e477056a66a80e65d1e631109d'}\n\n```{.r .cell-code}\n# Get the names of slots in the automl_models_h2o object\nslots <- slotNames(automl_model_h2o)\n\n# Access the leaderboard from the automl_models_h2o object\nleaderboard <- automl_model_h2o@leaderboard\nleaderboard\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                                                  model_id       auc   logloss\n#> 1 StackedEnsemble_BestOfFamily_3_AutoML_12_20230615_82640 0.9518686 0.1748054\n#> 2    StackedEnsemble_AllModels_2_AutoML_12_20230615_82640 0.9512450 0.1751240\n#> 3 StackedEnsemble_BestOfFamily_2_AutoML_12_20230615_82640 0.9508860 0.1767061\n#> 4    StackedEnsemble_AllModels_1_AutoML_12_20230615_82640 0.9506600 0.1761617\n#> 5                          GBM_4_AutoML_12_20230615_82640 0.9495704 0.1782795\n#> 6                          GBM_3_AutoML_12_20230615_82640 0.9470881 0.1838058\n#>       aucpr mean_per_class_error      rmse        mse\n#> 1 0.7226038            0.1324578 0.2288391 0.05236731\n#> 2 0.7212276            0.1187951 0.2300424 0.05291952\n#> 3 0.7176618            0.1493571 0.2297406 0.05278074\n#> 4 0.7188289            0.1348982 0.2306037 0.05317805\n#> 5 0.7163029            0.1403840 0.2308283 0.05328171\n#> 6 0.7004171            0.1203357 0.2352896 0.05536118\n#> \n#> [14 rows x 7 columns]\n```\n:::\n:::\n\n::: {.cell hash='03_Challenge3_automated_machine_learning_with_h20_1_cache/html/unnamed-chunk-6_36464d2785fea88fa43883edf528ef9b'}\n\n```{.r .cell-code}\n# Extract the name of a specific model from the leaderboard\nget_model_name <- function(h2o_leaderboard, n = 1, verbose = T) {\n  \n  model_name <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(n) %>%\n    pull(model_id)\n  \n  if (verbose) message(model_name)\n  \n  return(model_name)\n  \n}\n\n# Get the name of the 6th model in the leaderboard\nmodel_name <- automl_model_h2o@leaderboard %>% \n  get_model_name(1) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> StackedEnsemble_BestOfFamily_3_AutoML_12_20230615_82640\n```\n:::\n\n```{.r .cell-code}\n# Save the specified model\n#h2o.getModel(\"StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\") %>% \n#h2o.saveModel(path = \"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/\")\n\n\n# Load a specific model\nloaded_model <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\")\n```\n:::\n\n\n\n## 5.Predicting using Leader Model\n\n::: {.cell hash='03_Challenge3_automated_machine_learning_with_h20_1_cache/html/unnamed-chunk-7_66cff1f7eb30680c1e04817f1dfe6bc3'}\n\n```{.r .cell-code}\n# Generate predictions using the Stacked Ensemble model\npredictions <- h2o.predict(loaded_model, newdata = as.h2o(test_h2o))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Check the type of the predictions object\npred_type <- typeof(predictions)\n\n# Convert predictions to a tibble\npredictions_tbl <- as_tibble(predictions)\nsaveRDS(predictions_tbl, \"/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/predictions_tbl.rds\")\nView(predictions_tbl)\n\nknitr::include_graphics(\"/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/went_back_prediction.png\")\n```\n\n::: {.cell-output-display}\n![](../../went_back_prediction.png){width=192}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
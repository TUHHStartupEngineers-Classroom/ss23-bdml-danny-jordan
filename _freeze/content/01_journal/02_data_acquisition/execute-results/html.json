{
  "hash": "01543cb0a9b46dea0745ae5837ecbace",
  "result": {
    "markdown": "---\ntitle: \"Data Acquisition\"\nauthor: \"Danny Jordan\"\n---\n\n\n# Download the bike json file and open it\n\n\n::: {.cell hash='02_data_acquisition_cache/html/unnamed-chunk-1_a7d66072aca5b3fc7410473a989a8bf6'}\n\n```{.r .cell-code}\nlibrary(jsonlite)\nbike_data_lst <- fromJSON(\"02_data_acquisition/bike_data.json\")\n# Open the data by clicking on it in the environment or by running View()\nView(bike_data_lst)\ndisplay_value <- bike_data_lst$productDetail$variationAttributes$values[[1]]$displayValue\n```\n:::\n\n\n# Load all important Libraries for Webscraping\n\n::: {.cell hash='02_data_acquisition_cache/html/unnamed-chunk-2_a844a8c6cdedcbc97ac49e9fdbbf0cad'}\n\n```{.r .cell-code}\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\nlibrary(rvest)     # HTML Hacking & Web Scraping\nlibrary(xopen)     # Quickly opening URLs\nlibrary(jsonlite)  # converts JSON files to R objects\nlibrary(glue)      # concatenate strings\nlibrary(stringi)   # character string/text processing\nlibrary(xopen) \n\nurl_home          <- \"https://www.canyon.com/en-de\"\n#xopen(url_home) # Open links directly from RStudio to inspect them\n\n# Read in the HTML for the entire webpage\nhtml_home         <- read_html(url_home)\n\n# Web scrape the ids for the families\nbike_family_tbl <- html_home %>%\n\n# Get the nodes for the families ...\n\nhtml_elements(css = \".header__navBarPreloadItem--level1\")  %>% \nhtml_text()  %>% \n\ndiscard(.p = ~stringr::str_detect(.x,\"Gear|Outlet|Service\")) %>%\n  \n# Convert vector to tibble\nenframe(name = \"position\", value = \"family_class\") %>%\n\n# Add a hashtag so we can get nodes of the categories by id (#)\nmutate(\n   family_id = str_glue(\"#{family_class}\")\n)\n```\n:::\n\n\n\n# Tried to use OpenWeatherMap API, but after problems (maybe due to activation of API Key) I used an\n# open API with Rick and Morty data and accessed 3 characters\n\n::: {.cell hash='02_data_acquisition_cache/html/unnamed-chunk-3_49680b67a7f8a502faa638b9df9bb030'}\n\n```{.r .cell-code}\n# Load necessary packages\nlibrary(httr)\nlibrary(jsonlite)\n\n# Set the URL for the API request\nurl <- \"https://rickandmortyapi.com/api/character\"\n\n# Make a GET request to the API\nresponse <- GET(url)\n\n# Check the status of the request\nstop_for_status(response)\n\n# Parse the content of the response\ncontent <- content(response, \"text\")\n\n# Convert the JSON content into a list\ncharacter_data <- fromJSON(content)\n\n# Print the character data\nprint(character_data)\n\n# Select characters with IDs 1, 2 and 3\nselected_characters <- character_data$results[character_data$results$id %in% c(1, 2, 3), ]\n\n# Print the data for these characters\nprint(selected_characters)\n```\n:::\n\n\n![Revenue by years](02_data_acquisition/figure-html/print_out_API_rick_and_morty.png)\n\n# Challenge 2.b\n# Scrape one of the competitor websites of canyon: Chose Rosebike\n\n# 1.0 LIBRARIES ----\n\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\nlibrary(rvest)     # HTML Hacking & Web Scraping\nlibrary(xopen)     # Quickly opening URLs\nlibrary(jsonlite)  # converts JSON files to R objects\nlibrary(glue)      # concatenate strings\nlibrary(stringi)   # character string/text processing\n\n# 1.1 COLLECT PRODUCT FAMILIES ----\n\nurl_home <- \"https://www.rosebikes.com/\"\n\n# Read in the HTML for the entire webpage\nhtml_home <- read_html(url_home)\n\n# Web scrape the ids for the families\nbike_family_tbl <- html_home %>%\n  # Get the nodes for the families ...\n  html_nodes(css = \".main-navigation-category-bikes__title .main-navigation-category-bikes-level-3__list-item:nth-child(1) .main-navigation-item__title\") %>%\n  # ...and extract the information of the id attribute\n  html_text()\n\n# Print the bike_family_tbl\nprint(bike_family_tbl)\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "a5dfd754651a215aea7346c5ad0fdfc8",
  "result": {
    "markdown": "---\ntitle: \"Performance Meassures\"\nauthor: \"Danny Jordan\"\n---\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-1_02675c034ab66351ad8a7fb4fc82f8cd'}\n\n```{.r .cell-code}\n# Required Libraries\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n```\n:::\n\n```{.r .cell-code}\nlibrary(rsample)\nlibrary(h2o)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n#> \n#> \n#> Attaching package: 'h2o'\n#> \n#> The following objects are masked from 'package:lubridate':\n#> \n#>     day, hour, month, week, year\n#> \n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n#> \n#> The following objects are masked from 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n```\n:::\n\n```{.r .cell-code}\n# Initialize H2O\nh2o_connection <- h2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         2 hours 3 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 17 days \n#>     H2O cluster name:           H2O_started_from_R_jorda_ktd724 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.10 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n```\n:::\n\n```{.r .cell-code}\n# Read and Split Data\nproduct_backorders_tbl <- read_csv(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n#test print\n#product_backorders_tbl\nset_seed <- 1205\nsplit_obj <- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_data_tbl <- training(split_obj)\ntest_data_tbl <- testing(split_obj)\n\n# Data Preparation\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_data_tbl) %>%\n  step_zv(all_predictors()) %>%\n  prep()\n\ntrain_prepared_tbl <- bake(recipe_obj, new_data = train_data_tbl)\ntest_prepared_tbl <- bake(recipe_obj, new_data = test_data_tbl)\n\n# Divide the data into a training and a validation data frame\n# The seed is set for the sake of reproducibility\nsplit_h2o <- h2o.splitFrame(as.h2o(train_prepared_tbl), ratios = c(0.85), seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_prepared_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Define the response variable\ntarget_variable <- \"went_on_backorder\"\n\n# Define the predictor variables\nfeature_variables <- setdiff(names(train_h2o), target_variable)\n\n# Run automated machine learning\nautoml_model_h2o <- h2o.automl(\n  x = feature_variables,\n  y = target_variable,\n  training_frame = train_h2o,\n  validation_frame = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs = 30,\n  nfolds = 5\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n#> 08:28:29.910: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 08:28:29.912: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |==========================================================            |  84%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Check the type of the automl_model_h2o object\nmodel_type <- typeof(automl_model_h2o)\n```\n:::\n\n\n\n# 1. Leaderboard visualization\n\n\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-2_555525d81745f57389d5257bc0ad21f7'}\n\n```{.r .cell-code}\n# Visualize the H2O leaderboard to help with model selection\ndata_transformed_tbl <- automl_model_h2o@leaderboard %>%\n  \n# Step 1: Get the leaderboard from the H2O AutoML model and convert   it to a tibble\n  as.tibble() %>%\n\n# Step 2: Exclude certain columns from the tibble\n  select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n  \n# Step 3: Extract the model type from the model ID and create a new   column\n  mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n  \n# Step 4: Select the top 15 models from the leaderboard\n  slice(1:15) %>% \n  \n# Step 5: Convert the rownames to a new column\n  rownames_to_column(var = \"rowname\") %>%\n  \n#Step 6: Reorder the factors in the model_id and model_type columns\n  mutate(\n    model_id   = as_factor(model_id) %>% reorder(auc),\n    model_type = as_factor(model_type)\n    \n# Step 7: Transform the tibble from wide to long format\n  ) %>% \n  pivot_longer(cols = -c(model_id, model_type, rowname), \n               names_to = \"key\", \n               values_to = \"value\", \n               names_transform = list(key = forcats::fct_inorder)\n  ) %>% \n  \n# Step 8: Modify the model_id column by combining it with the rowname and reverse the order\n  mutate(model_id = paste0(rowname, \". \", model_id) %>% as_factor() %>% fct_rev())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#> ℹ Please use `as_tibble()` instead.\n#> ℹ The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n```{.r .cell-code}\ndata_transformed_tbl %>%\n  ggplot(aes(value, model_id, color = model_type)) +\n  geom_point(size = 3) +\n  geom_label(aes(label = round(value, 2), hjust = \"inward\")) +\n  \n  # Facet to break out logloss and auc\n  facet_wrap(~ key, scales = \"free_x\") +\n  labs(title = \"Leaderboard Metrics\",\n       subtitle = paste0(\"Ordered by: \", \"auc\"),\n       y = \"Model Postion, Model ID\", x = \"\") + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](04_Challenge4_performance_measures_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_h2o_leaderboard <- function(h2o_leaderboard, order_by = c(\"auc\", \"logloss\"), \n                                 n_max = 20, size = 4, include_lbl = TRUE) {\n  \n  # Setup inputs\n  # adjust input so that all formats are working\n  order_by <- tolower(order_by[[1]])\n  \n  leaderboard_tbl <- h2o_leaderboard@leaderboard %>%\n    as.tibble() %>%\n    select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n    mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n    rownames_to_column(var = \"rowname\") %>%\n    mutate(model_id = paste0(rowname, \". \", model_id) %>% as_factor())\n  \n  # Transformation\n  if (order_by == \"auc\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(auc),\n        model_type = as_factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else if (order_by == \"logloss\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(logloss) %>% fct_rev(),\n        model_type = as_factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else {\n    # If nothing is supplied\n    stop(paste0(\"order_by = '\", order_by, \"' is not a permitted option.\"))\n  }\n  \n  # Visualization\n  g <- data_transformed_tbl %>%\n    ggplot(aes(value, model_id, color = model_type)) +\n    geom_point(size = size) +\n    facet_wrap(~ key, scales = \"free_x\") +\n    labs(title = \"Leaderboard Metrics\",\n         subtitle = paste0(\"Ordered by: \", toupper(order_by)),\n         y = \"Model Postion, Model ID\", x = \"\")\n  \n  if (include_lbl) g <- g + geom_label(aes(label = round(value, 2), \n                                           hjust = \"inward\"))\n  \n  return(g)\n  \n}\n```\n:::\n\n\n\n#2 Tune a model with grid search\n\n\ndeeplearning_h2o <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\")\n\n# Take a look for the metrics on the training data set\n# For my model the total error in the confusion matrix is ~15 %\ndeeplearning_h2o\n\n# We want to see how it performs for the testing data frame\ntest_h2o\n\n# Make sure to convert it to an h20 object\n# Accuracy of the confusion matrix shows ~85 % accuracy\nh2o.performance(deeplearning_h2o, newdata = as.h2o(test_h2o))\n\n\ndeeplearning_grid_01 <- h2o.grid(\n  \n  # See help page for available algos\n  algorithm = \"deeplearning\",\n  \n  # I just use the same as the object\n  #grid_id = \"deeplearning_grid_01\",\n  \n  # The following is for ?h2o.deeplearning()\n  # predictor and response variables\n  y = target_variable,\n  x = feature_variables,\n  \n  # training and validation frame and crossfold validation\n  training_frame   = train_h2o,\n  validation_frame = valid_h2o,\n  nfolds = 5,\n  \n  # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n  hyper_params = list(\n    # Use some combinations (the first one was the original)\n    hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n    epochs = c(10, 50, 100)\n  )\n)\n\ndeeplearning_grid_01\n\nh2o.getGrid(grid_id = \"deeplearning_grid_01\", sort_by = \"auc\", decreasing = TRUE)\n\ndeeplearning_grid_01_model_1 <- h2o.getModel(\"deeplearning_grid_01_model_1\")\n\ndeeplearning_grid_01_model_1 %>% h2o.auc(train = T, valid = T, xval = T)\n\n# We can tell the model is overfitting because of the huge difference between training AUC and the validation / cross validation AUC\n\n# Run it on the test data\ndeeplearning_grid_01_model_1 %>%\n  h2o.performance(newdata = as.h2o(test_h2o))\n\n\n\n\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-3_8b44c8f3d182800a0bb0608d47c3fe33'}\n\n```{.r .cell-code}\nstacked_ensemble_h2o <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\")\nGBM_h2o <- h2o.loadModel(\"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/GBM_1_AutoML_1_20230612_230009\")\n\nperformance_h2o_stacked <- h2o.performance(stacked_ensemble_h2o, newdata = as.h2o(test_h2o))\nperformance_h2o_gbm <- h2o.performance(GBM_h2o, newdata = as.h2o(test_h2o))\n\ntypeof(performance_h2o_stacked)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"S4\"\n```\n:::\n\n```{.r .cell-code}\nperformance_h2o_stacked %>% slotNames()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"algorithm\" \"on_train\"  \"on_valid\"  \"on_xval\"   \"metrics\"\n```\n:::\n\n```{.r .cell-code}\n# We are focusing on the slot metrics. This slot contains all possible metrics\nperformance_h2o_stacked@metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> $model\n#> $model$`__meta`\n#> $model$`__meta`$schema_version\n#> [1] 3\n#> \n#> $model$`__meta`$schema_name\n#> [1] \"ModelKeyV3\"\n#> \n#> $model$`__meta`$schema_type\n#> [1] \"Key<Model>\"\n#> \n#> \n#> $model$name\n#> [1] \"StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\"\n#> \n#> $model$type\n#> [1] \"Key<Model>\"\n#> \n#> $model$URL\n#> [1] \"/3/Models/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046\"\n#> \n#> \n#> $model_checksum\n#> [1] \"-8682890534361748960\"\n#> \n#> $frame\n#> $frame$name\n#> [1] \"test_h2o_sid_a5e5_144\"\n#> \n#> \n#> $frame_checksum\n#> [1] \"1414251131096891176\"\n#> \n#> $description\n#> NULL\n#> \n#> $scoring_time\n#> [1] 1.686811e+12\n#> \n#> $predictions\n#> NULL\n#> \n#> $MSE\n#> [1] 0.03713402\n#> \n#> $RMSE\n#> [1] 0.1927019\n#> \n#> $nobs\n#> [1] 2858\n#> \n#> $custom_metric_name\n#> NULL\n#> \n#> $custom_metric_value\n#> [1] 0\n#> \n#> $r2\n#> [1] 0.6457076\n#> \n#> $logloss\n#> [1] 0.1278478\n#> \n#> $AUC\n#> [1] 0.9753732\n#> \n#> $pr_auc\n#> [1] 0.859624\n#> \n#> $Gini\n#> [1] 0.9507464\n#> \n#> $mean_per_class_error\n#> [1] 0.1157676\n#> \n#> $domain\n#> [1] \"No\"  \"Yes\"\n#> \n#> $cm\n#> $cm$`__meta`\n#> $cm$`__meta`$schema_version\n#> [1] 3\n#> \n#> $cm$`__meta`$schema_name\n#> [1] \"ConfusionMatrixV3\"\n#> \n#> $cm$`__meta`$schema_type\n#> [1] \"ConfusionMatrix\"\n#> \n#> \n#> $cm$table\n#> Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n#>          No Yes  Error          Rate\n#> No     2446  72 0.0286 =  72 / 2,518\n#> Yes      69 271 0.2029 =    69 / 340\n#> Totals 2515 343 0.0493 = 141 / 2,858\n#> \n#> \n#> $thresholds_and_metric_scores\n#> Metrics for Thresholds: Binomial metrics as a function of classification thresholds\n#>   threshold       f1       f2 f0point5 accuracy precision   recall specificity\n#> 1  0.997446 0.017493 0.011005 0.042614 0.882085  1.000000 0.008824    1.000000\n#> 2  0.994694 0.034682 0.021962 0.082418 0.883135  1.000000 0.017647    1.000000\n#> 3  0.988375 0.045977 0.029240 0.107527 0.883835  1.000000 0.023529    1.000000\n#> 4  0.985202 0.051576 0.032871 0.119681 0.884185  1.000000 0.026471    1.000000\n#> 5  0.979324 0.062678 0.040117 0.143229 0.884885  1.000000 0.032353    1.000000\n#>   absolute_mcc min_per_class_accuracy mean_per_class_accuracy  tns fns fps tps\n#> 1     0.088216               0.008824                0.504412 2518 337   0   3\n#> 2     0.124821               0.017647                0.508824 2518 334   0   6\n#> 3     0.144182               0.023529                0.511765 2518 332   0   8\n#> 4     0.152955               0.026471                0.513235 2518 331   0   9\n#> 5     0.169157               0.032353                0.516176 2518 329   0  11\n#>        tnr      fnr      fpr      tpr idx\n#> 1 1.000000 0.991176 0.000000 0.008824   0\n#> 2 1.000000 0.982353 0.000000 0.017647   1\n#> 3 1.000000 0.976471 0.000000 0.023529   2\n#> 4 1.000000 0.973529 0.000000 0.026471   3\n#> 5 1.000000 0.967647 0.000000 0.032353   4\n#> \n#> ---\n#>     threshold       f1       f2 f0point5 accuracy precision   recall\n#> 395  0.001131 0.238429 0.439050 0.163650 0.240028  0.135350 1.000000\n#> 396  0.000866 0.233436 0.432240 0.159895 0.218684  0.132141 1.000000\n#> 397  0.000628 0.226365 0.422465 0.154602 0.186844  0.127628 1.000000\n#> 398  0.000398 0.220279 0.413927 0.150071 0.157803  0.123771 1.000000\n#> 399  0.000182 0.212766 0.403226 0.144509 0.119664  0.119048 1.000000\n#> 400  0.000037 0.212633 0.403035 0.144410 0.118964  0.118964 1.000000\n#>     specificity absolute_mcc min_per_class_accuracy mean_per_class_accuracy tns\n#> 395    0.137411     0.136377               0.137411                0.568705 346\n#> 396    0.113185     0.122297               0.113185                0.556593 285\n#> 397    0.077045     0.099162               0.077045                0.538523 194\n#> 398    0.044083     0.073866               0.044083                0.522041 111\n#> 399    0.000794     0.009724               0.000794                0.500397   2\n#> 400    0.000000     0.000000               0.000000                0.500000   0\n#>     fns  fps tps      tnr      fnr      fpr      tpr idx\n#> 395   0 2172 340 0.137411 0.000000 0.862589 1.000000 394\n#> 396   0 2233 340 0.113185 0.000000 0.886815 1.000000 395\n#> 397   0 2324 340 0.077045 0.000000 0.922955 1.000000 396\n#> 398   0 2407 340 0.044083 0.000000 0.955917 1.000000 397\n#> 399   0 2516 340 0.000794 0.000000 0.999206 1.000000 398\n#> 400   0 2518 340 0.000000 0.000000 1.000000 1.000000 399\n#> \n#> $max_criteria_and_metric_scores\n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.377706    0.793558 181\n#> 2                       max f2  0.143508    0.835987 261\n#> 3                 max f0point5  0.538587    0.831006 141\n#> 4                 max accuracy  0.478325    0.953464 156\n#> 5                max precision  0.997446    1.000000   0\n#> 6                   max recall  0.005501    1.000000 382\n#> 7              max specificity  0.997446    1.000000   0\n#> 8             max absolute_mcc  0.478325    0.767372 156\n#> 9   max min_per_class_accuracy  0.148315    0.918586 259\n#> 10 max mean_per_class_accuracy  0.138768    0.921815 264\n#> 11                     max tns  0.997446 2518.000000   0\n#> 12                     max fns  0.997446  337.000000   0\n#> 13                     max fps  0.000037 2518.000000 399\n#> 14                     max tps  0.005501  340.000000 382\n#> 15                     max tnr  0.997446    1.000000   0\n#> 16                     max fnr  0.997446    0.991176   0\n#> 17                     max fpr  0.000037    1.000000 399\n#> 18                     max tpr  0.005501    1.000000 382\n#> \n#> $gains_lift_table\n#> Gains/Lift Table: Avg response rate: 11.90 %, avg score: 11.78 %\n#>    group cumulative_data_fraction lower_threshold     lift cumulative_lift\n#> 1      1               0.01014696        0.954918 8.405882        8.405882\n#> 2      2               0.02029391        0.918065 7.536308        7.971095\n#> 3      3               0.03009097        0.878561 7.805462        7.917168\n#> 4      4               0.04023793        0.842280 7.826166        7.894220\n#> 5      5               0.05003499        0.803527 7.505252        7.818058\n#> 6      6               0.10006998        0.516111 6.583628        7.200843\n#> 7      7               0.15010497        0.242589 2.880337        5.760675\n#> 8      8               0.20013996        0.115529 1.469560        4.687896\n#> 9      9               0.30020994        0.038808 0.470259        3.282017\n#> 10    10               0.39993002        0.019265 0.088483        2.485729\n#> 11    11               0.50000000        0.012350 0.029391        1.994118\n#> 12    12               0.60006998        0.007684 0.000000        1.661571\n#> 13    13               0.69979006        0.004287 0.029494        1.429000\n#> 14    14               0.79986004        0.002025 0.000000        1.250219\n#> 15    15               0.89993002        0.000762 0.000000        1.111198\n#> 16    16               1.00000000        0.000000 0.000000        1.000000\n#>    response_rate    score cumulative_response_rate cumulative_score\n#> 1       1.000000 0.977545                 1.000000         0.977545\n#> 2       0.896552 0.933025                 0.948276         0.955285\n#> 3       0.928571 0.895426                 0.941860         0.935796\n#> 4       0.931034 0.859738                 0.939130         0.916616\n#> 5       0.892857 0.823272                 0.930070         0.898339\n#> 6       0.783217 0.668659                 0.856643         0.783499\n#> 7       0.342657 0.357524                 0.685315         0.641507\n#> 8       0.174825 0.168206                 0.557692         0.523182\n#> 9       0.055944 0.067783                 0.390443         0.371382\n#> 10      0.010526 0.027251                 0.295713         0.285575\n#> 11      0.003497 0.015539                 0.237229         0.231530\n#> 12      0.000000 0.009906                 0.197668         0.194571\n#> 13      0.003509 0.006046                 0.170000         0.167707\n#> 14      0.000000 0.002995                 0.148731         0.147100\n#> 15      0.000000 0.001364                 0.132193         0.130894\n#> 16      0.000000 0.000380                 0.118964         0.117834\n#>    capture_rate cumulative_capture_rate        gain cumulative_gain\n#> 1      0.085294                0.085294  740.588235      740.588235\n#> 2      0.076471                0.161765  653.630832      697.109533\n#> 3      0.076471                0.238235  680.546218      691.716826\n#> 4      0.079412                0.317647  682.616633      689.421995\n#> 5      0.073529                0.391176  650.525210      681.805841\n#> 6      0.329412                0.720588  558.362814      620.084327\n#> 7      0.144118                0.864706  188.033731      476.067462\n#> 8      0.073529                0.938235   46.955985      368.789593\n#> 9      0.047059                0.985294  -52.974085      228.201700\n#> 10     0.008824                0.994118  -91.151703      148.572899\n#> 11     0.002941                0.997059  -97.060880       99.411765\n#> 12     0.000000                0.997059 -100.000000       66.157091\n#> 13     0.002941                1.000000  -97.050568       42.900000\n#> 14     0.000000                1.000000 -100.000000       25.021872\n#> 15     0.000000                1.000000 -100.000000       11.119751\n#> 16     0.000000                1.000000 -100.000000        0.000000\n#>    kolmogorov_smirnov\n#> 1            0.085294\n#> 2            0.160573\n#> 3            0.236250\n#> 4            0.314867\n#> 5            0.387205\n#> 6            0.704305\n#> 7            0.811092\n#> 8            0.837759\n#> 9            0.777590\n#> 10           0.674419\n#> 11           0.564176\n#> 12           0.450593\n#> 13           0.340747\n#> 14           0.227164\n#> 15           0.113582\n#> 16           0.000000\n#> \n#> $residual_deviance\n#> [1] 730.7778\n#> \n#> $null_deviance\n#> [1] 2085.574\n#> \n#> $AIC\n#> [1] 738.7778\n#> \n#> $null_degrees_of_freedom\n#> [1] 2857\n#> \n#> $residual_degrees_of_freedom\n#> [1] 2854\n```\n:::\n\n```{.r .cell-code}\n# Classifier Summary Metrics\n\nh2o.auc(performance_h2o_stacked, train = TRUE, valid = TRUE, xval = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.9753732\n```\n:::\n\n```{.r .cell-code}\n# Caution: \"train, \"val\", and \"xval\" arguments only work for models (not performance objects)\nh2o.auc(stacked_ensemble_h2o, train = TRUE, valid = TRUE, xval = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     train     valid      xval \n#> 0.9898581 0.9540598 0.9527319\n```\n:::\n\n```{.r .cell-code}\nh2o.giniCoef(performance_h2o_stacked)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.9507464\n```\n:::\n\n```{.r .cell-code}\nh2o.logloss(performance_h2o_stacked)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.1278478\n```\n:::\n\n```{.r .cell-code}\nh2o.confusionMatrix(stacked_ensemble_h2o)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"No\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Yes\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Rate\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"8579\",\"2\":\"152\",\"3\":\"0.01740923\",\"4\":\"=152/8731\",\"_rn_\":\"No\"},{\"1\":\"177\",\"2\":\"980\",\"3\":\"0.15298185\",\"4\":\"=177/1157\",\"_rn_\":\"Yes\"},{\"1\":\"8756\",\"2\":\"1132\",\"3\":\"0.03327265\",\"4\":\"=329/9888\",\"_rn_\":\"Totals\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Result for the holdout set\nh2o.confusionMatrix(performance_h2o_stacked)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"No\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Yes\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Error\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Rate\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"2446\",\"2\":\"72\",\"3\":\"0.02859412\",\"4\":\"=72/2518\",\"_rn_\":\"No\"},{\"1\":\"69\",\"2\":\"271\",\"3\":\"0.20294118\",\"4\":\"=69/340\",\"_rn_\":\"Yes\"},{\"1\":\"2515\",\"2\":\"343\",\"3\":\"0.04933520\",\"4\":\"=141/2858\",\"_rn_\":\"Totals\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Precision vs Recall Plot\n\n# This is on the test set\nperformance_tbl_stacked <- performance_h2o_stacked %>%\n  h2o.metric() %>%\n  as.tibble() \n\nperformance_tbl_stacked %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 400\n#> Columns: 20\n#> $ threshold               <dbl> 0.9974459, 0.9946936, 0.9883745, 0.9852018, 0.…\n#> $ f1                      <dbl> 0.01749271, 0.03468208, 0.04597701, 0.05157593…\n#> $ f2                      <dbl> 0.01100514, 0.02196193, 0.02923977, 0.03287071…\n#> $ f0point5                <dbl> 0.04261364, 0.08241758, 0.10752688, 0.11968085…\n#> $ accuracy                <dbl> 0.8820854, 0.8831351, 0.8838348, 0.8841847, 0.…\n#> $ precision               <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ recall                  <dbl> 0.008823529, 0.017647059, 0.023529412, 0.02647…\n#> $ specificity             <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ absolute_mcc            <dbl> 0.08821572, 0.12482146, 0.14418197, 0.15295491…\n#> $ min_per_class_accuracy  <dbl> 0.008823529, 0.017647059, 0.023529412, 0.02647…\n#> $ mean_per_class_accuracy <dbl> 0.5044118, 0.5088235, 0.5117647, 0.5132353, 0.…\n#> $ tns                     <dbl> 2518, 2518, 2518, 2518, 2518, 2518, 2518, 2518…\n#> $ fns                     <dbl> 337, 334, 332, 331, 329, 327, 325, 320, 316, 3…\n#> $ fps                     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ tps                     <dbl> 3, 6, 8, 9, 11, 13, 15, 20, 24, 25, 26, 28, 29…\n#> $ tnr                     <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ fnr                     <dbl> 0.9911765, 0.9823529, 0.9764706, 0.9735294, 0.…\n#> $ fpr                     <dbl> 0.0000000000, 0.0000000000, 0.0000000000, 0.00…\n#> $ tpr                     <dbl> 0.008823529, 0.017647059, 0.023529412, 0.02647…\n#> $ idx                     <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, …\n```\n:::\n\n```{.r .cell-code}\ntheme_new <- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"black\", fill = NA, linewidth = 0.5),\n  panel.grid.major = element_line(color = \"grey\", size = 0.333)\n) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n#> ℹ Please use the `linewidth` argument instead.\n```\n:::\n\n```{.r .cell-code}\nperformance_tbl_stacked %>%\n  filter(f1 == max(f1))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"threshold\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f1\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f2\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f0point5\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"accuracy\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"precision\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"recall\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"specificity\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"absolute_mcc\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"min_per_class_accuracy\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"mean_per_class_accuracy\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tns\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fns\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fps\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tps\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tnr\"],\"name\":[16],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fnr\"],\"name\":[17],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"fpr\"],\"name\":[18],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tpr\"],\"name\":[19],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"idx\"],\"name\":[20],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.3777061\",\"2\":\"0.7935578\",\"3\":\"0.7956547\",\"4\":\"0.791472\",\"5\":\"0.9506648\",\"6\":\"0.7900875\",\"7\":\"0.7970588\",\"8\":\"0.9714059\",\"9\":\"0.7655529\",\"10\":\"0.7970588\",\"11\":\"0.8842324\",\"12\":\"2446\",\"13\":\"69\",\"14\":\"72\",\"15\":\"271\",\"16\":\"0.9714059\",\"17\":\"0.2029412\",\"18\":\"0.02859412\",\"19\":\"0.7970588\",\"20\":\"181\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nperformance_tbl_stacked %>%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"blue\", size = 1) +\n  geom_line(aes(y = recall), color = \"red\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o_stacked, \"f1\")) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](04_Challenge4_performance_measures_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n# ROC Plot\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-4_bdf5ea7d0ff47acf1374a40e48fb4f59'}\n\n```{.r .cell-code}\npath <- \"Challeng3_automated_machine_learning_h2O/StackedEnsemble_AllModels_1_AutoML_1_20230610_174902\"\n\nload_model_performance_metrics <- function(path, test_h2o) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_h2o)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc)\n  \n}\n\nmodel_metrics_tbl <- fs::dir_info(path = \"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/\") %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_h2o)) %>%\n  unnest(cols = metrics)\n\nmodel_metrics_tbl %>%\n  mutate(\n    # Extract the model names\n    path = str_extract(path, \"(?<=/)[^/]+$\") %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(fpr, tpr, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  \n  # just for demonstration purposes\n  geom_abline(color = \"red\", linetype = \"dotted\") +\n  \n  theme_new +\n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"ROC Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_Challenge4_performance_measures_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n# Precision vs Recall plot\n\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-5_8ab05a6ad73835a62ed8d213714a0865'}\n\n```{.r .cell-code}\n# Precision vs Recall\n\nload_model_performance_metrics <- function(path, test_tbl) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc, precision, recall)\n  \n}\n\nmodel_metrics_tbl <- fs::dir_info(path = \"C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/\") %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_h2o)) %>%\n  unnest(cols = metrics)\n\nmodel_metrics_tbl %>%\n  mutate(\n    path = str_extract(path, \"(?<=/)[^/]+$\") %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(recall, precision, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  theme_new + \n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"Precision vs Recall Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_Challenge4_performance_measures_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n# Gain Plot\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-6_9e8b219d5d5406081ce8e9dc064a99a5'}\n\n```{.r .cell-code}\n # Gain & Lift\npredictions_tbl <- readRDS(\"/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/predictions_tbl.rds\")\nranked_predictions_tbl <- predictions_tbl %>%\n  bind_cols(as.data.frame(test_h2o)\n) %>%\n  select(predict:No, went_on_backorder) %>%\n  # Sorting from highest to lowest class probability\n  arrange(desc(No))\n\nranked_predictions_tbl %>%\n  mutate(ntile = ntile(No, n = 10)) %>%\n  group_by(ntile) %>%\n  summarise(\n    cases = n(),\n    responses = sum(went_on_backorder == \"No\")\n  ) %>%\n  arrange(desc(ntile))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"ntile\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"cases\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"responses\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"10\",\"2\":\"285\",\"3\":\"285\"},{\"1\":\"9\",\"2\":\"285\",\"3\":\"285\"},{\"1\":\"8\",\"2\":\"286\",\"3\":\"286\"},{\"1\":\"7\",\"2\":\"286\",\"3\":\"286\"},{\"1\":\"6\",\"2\":\"286\",\"3\":\"286\"},{\"1\":\"5\",\"2\":\"286\",\"3\":\"286\"},{\"1\":\"4\",\"2\":\"286\",\"3\":\"284\"},{\"1\":\"3\",\"2\":\"286\",\"3\":\"275\"},{\"1\":\"2\",\"2\":\"286\",\"3\":\"209\"},{\"1\":\"1\",\"2\":\"286\",\"3\":\"36\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ncalculated_gain_lift_tbl <- ranked_predictions_tbl %>%\n  mutate(ntile = ntile(No, n = 10)) %>%\n  group_by(ntile) %>%\n  summarise(\n    cases = n(),\n    responses = sum(went_on_backorder == \"No\")\n  ) %>%\n  arrange(desc(ntile)) %>%\n  \n  # Add group numbers (opposite of ntile)\n  mutate(group = row_number()) %>%\n  select(group, cases, responses) %>%\n  \n  # Calculations\n  mutate(\n    cumulative_responses = cumsum(responses),\n    pct_responses        = responses / sum(responses),\n    gain                 = cumsum(pct_responses),\n    cumulative_pct_cases = cumsum(cases) / sum(cases),\n    lift                 = gain / cumulative_pct_cases,\n    gain_baseline        = cumulative_pct_cases,\n    lift_baseline        = gain_baseline / cumulative_pct_cases\n  )\n\ncalculated_gain_lift_tbl \n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"group\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"cases\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"responses\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"cumulative_responses\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"pct_responses\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"gain\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cumulative_pct_cases\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"lift\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"gain_baseline\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"lift_baseline\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"285\",\"3\":\"285\",\"4\":\"285\",\"5\":\"0.11318507\",\"6\":\"0.1131851\",\"7\":\"0.09972008\",\"8\":\"1.135028\",\"9\":\"0.09972008\",\"10\":\"1\"},{\"1\":\"2\",\"2\":\"285\",\"3\":\"285\",\"4\":\"570\",\"5\":\"0.11318507\",\"6\":\"0.2263701\",\"7\":\"0.19944017\",\"8\":\"1.135028\",\"9\":\"0.19944017\",\"10\":\"1\"},{\"1\":\"3\",\"2\":\"286\",\"3\":\"286\",\"4\":\"856\",\"5\":\"0.11358221\",\"6\":\"0.3399523\",\"7\":\"0.29951015\",\"8\":\"1.135028\",\"9\":\"0.29951015\",\"10\":\"1\"},{\"1\":\"4\",\"2\":\"286\",\"3\":\"286\",\"4\":\"1142\",\"5\":\"0.11358221\",\"6\":\"0.4535346\",\"7\":\"0.39958013\",\"8\":\"1.135028\",\"9\":\"0.39958013\",\"10\":\"1\"},{\"1\":\"5\",\"2\":\"286\",\"3\":\"286\",\"4\":\"1428\",\"5\":\"0.11358221\",\"6\":\"0.5671168\",\"7\":\"0.49965010\",\"8\":\"1.135028\",\"9\":\"0.49965010\",\"10\":\"1\"},{\"1\":\"6\",\"2\":\"286\",\"3\":\"286\",\"4\":\"1714\",\"5\":\"0.11358221\",\"6\":\"0.6806990\",\"7\":\"0.59972008\",\"8\":\"1.135028\",\"9\":\"0.59972008\",\"10\":\"1\"},{\"1\":\"7\",\"2\":\"286\",\"3\":\"284\",\"4\":\"1998\",\"5\":\"0.11278793\",\"6\":\"0.7934869\",\"7\":\"0.69979006\",\"8\":\"1.133893\",\"9\":\"0.69979006\",\"10\":\"1\"},{\"1\":\"8\",\"2\":\"286\",\"3\":\"275\",\"4\":\"2273\",\"5\":\"0.10921366\",\"6\":\"0.9027006\",\"7\":\"0.79986004\",\"8\":\"1.128573\",\"9\":\"0.79986004\",\"10\":\"1\"},{\"1\":\"9\",\"2\":\"286\",\"3\":\"209\",\"4\":\"2482\",\"5\":\"0.08300238\",\"6\":\"0.9857029\",\"7\":\"0.89993002\",\"8\":\"1.095311\",\"9\":\"0.89993002\",\"10\":\"1\"},{\"1\":\"10\",\"2\":\"286\",\"3\":\"36\",\"4\":\"2518\",\"5\":\"0.01429706\",\"6\":\"1.0000000\",\"7\":\"1.00000000\",\"8\":\"1.000000\",\"9\":\"1.00000000\",\"10\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngain_lift_tbl <- performance_h2o_stacked %>%\n  h2o.gainsLift() %>%\n  as.tibble()\n\n## Gain Chart\n\ngain_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n```\n\n::: {.cell-output-display}\n![](04_Challenge4_performance_measures_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# Lift Plot\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-7_9eebdf42c4765c5e121664e7ac5e3717'}\n\n```{.r .cell-code}\n## Lift Plot\n\nlift_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"capture\")) %>%\n  mutate(baseline = 1) %>%\n  rename(lift = cumulative_lift) %>%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Lift Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Lift\"\n  ) +\n  theme_new\n```\n\n::: {.cell-output-display}\n![](04_Challenge4_performance_measures_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n# Cowplot Dashboard\n\n\n::: {.cell hash='04_Challenge4_performance_measures_cache/html/unnamed-chunk-8_a7cc123420b83cd281cf87cbb9b0a4ed'}\n\n```{.r .cell-code}\n# 5. Performance Visualization ----  \nlibrary(cowplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'cowplot'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following object is masked from 'package:lubridate':\n#> \n#>     stamp\n```\n:::\n\n```{.r .cell-code}\nlibrary(glue)\n\n\n# set values to test the function while building it\nh2o_leaderboard <- automl_model_h2o@leaderboard\nnewdata <- test_h2o\norder_by <- \"auc\"\nmax_models <- 4\nsize <- 1\n\nplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n  \n  # Inputs\n  \n  leaderboard_tbl <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(1:max_models)\n  \n  newdata_tbl <- newdata %>%\n    as_tibble()\n  \n  # Selecting the first, if nothing is provided\n  order_by      <- tolower(order_by[[1]]) \n  \n  # Convert string stored in a variable to column name (symbol)\n  order_by_expr <- rlang::sym(order_by)\n  \n  # Turn of the progress bars ( opposite h2o.show_progress())\n  h2o.no_progress()\n  \n  # 1. Model metrics\n  \n  get_model_performance_metrics <- function(model_id, test_h2o) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_h2o))\n    \n    perf_h2o %>%\n      h2o.metric() %>%\n      as.tibble() %>%\n      select(threshold, tpr, fpr, precision, recall)\n    \n  }\n  \n  model_metrics_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        # programmatically reorder factors depending on order_by\n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    )\n  \n  \n  # 1A. ROC Plot\n  \n  p1 <- model_metrics_tbl %>%\n    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n    theme(legend.direction = \"vertical\") \n  \n  \n  # 1B. Precision vs Recall\n  \n  p2 <- model_metrics_tbl %>%\n    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n    theme(legend.position = \"none\") \n  \n  \n  # 2. Gain / Lift\n  \n  get_gain_lift <- function(model_id, test_h2o) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_h2o)) \n    \n    perf_h2o %>%\n      h2o.gainsLift() %>%\n      as.tibble() %>%\n      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n    \n  }\n  \n  gain_lift_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc  = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    ) %>%\n    rename(\n      gain = cumulative_capture_rate,\n      lift = cumulative_lift\n    ) \n  \n  # 2A. Gain Plot\n  \n  p3 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, gain, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size,) +\n    geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Gain\",\n         x = \"Cumulative Data Fraction\", y = \"Gain\") +\n    theme(legend.position = \"none\")\n  \n  # 2B. Lift Plot\n  \n  p4 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, lift, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Lift\",\n         x = \"Cumulative Data Fraction\", y = \"Lift\") +\n    theme(legend.position = \"none\") \n  \n  \n  # Combine using cowplot\n  \n  # cowplot::get_legend extracts a legend from a ggplot object\n  p_legend <- get_legend(p1)\n  # Remove legend from p1\n  p1 <- p1 + theme(legend.position = \"none\")\n  \n  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n  p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n  \n  # cowplot::ggdraw() sets up a drawing layer\n  p_title <- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#2C3E50\")\n  \n  p_subtitle <- ggdraw() + \n    draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n               color = \"#2C3E50\")\n  \n  # Combine everything\n  ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n                   \n                   # Adjust the relative spacing, so that the legends always fits\n                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n  \n  h2o.show_progress()\n  \n  return(ret)\n  \n}\n\nautoml_model_h2o@leaderboard %>%\n  plot_h2o_performance(newdata = test_h2o, order_by = \"logloss\", \n                       size = 0.5, max_models = 4)\n```\n\n::: {.cell-output-display}\n![](04_Challenge4_performance_measures_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
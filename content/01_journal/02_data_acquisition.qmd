---
title: "Data Acquisition"
author: "Danny Jordan"
---

# Download the bike json file and open it

```{r, eval=FALSE, highlight=TRUE}

library(jsonlite)
bike_data_lst <- fromJSON("02_data_acquisition/bike_data.json")
# Open the data by clicking on it in the environment or by running View()
View(bike_data_lst)
display_value <- bike_data_lst$productDetail$variationAttributes$values[[1]]$displayValue

```

# Load all important Libraries for Webscraping
```{r, eval=FALSE, highlight=TRUE}
library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(xopen) 

url_home          <- "https://www.canyon.com/en-de"
#xopen(url_home) # Open links directly from RStudio to inspect them

# Read in the HTML for the entire webpage
html_home         <- read_html(url_home)

# Web scrape the ids for the families
bike_family_tbl <- html_home %>%

# Get the nodes for the families ...

html_elements(css = ".header__navBarPreloadItem--level1")  %>% 
html_text()  %>% 

discard(.p = ~stringr::str_detect(.x,"Gear|Outlet|Service")) %>%
  
# Convert vector to tibble
enframe(name = "position", value = "family_class") %>%

# Add a hashtag so we can get nodes of the categories by id (#)
mutate(
   family_id = str_glue("#{family_class}")
)

```


# Tried to use OpenWeatherMap API, but after problems (maybe due to activation of API Key) I used an
# open API with Rick and Morty data and accessed 3 characters
```{r, eval=FALSE, highlight=TRUE}
# Load necessary packages
library(httr)
library(jsonlite)

# Set the URL for the API request
url <- "https://rickandmortyapi.com/api/character"

# Make a GET request to the API
response <- GET(url)

# Check the status of the request
stop_for_status(response)

# Parse the content of the response
content <- content(response, "text")

# Convert the JSON content into a list
character_data <- fromJSON(content)

# Print the character data
print(character_data)

# Select characters with IDs 1, 2 and 3
selected_characters <- character_data$results[character_data$results$id %in% c(1, 2, 3), ]

# Print the data for these characters
print(selected_characters)

```

![Revenue by years](02_data_acquisition/figure-html/print_out_API_rick_and_morty.png)

# Challenge 2.b
# Scrape one of the competitor websites of canyon: Chose Rosebike

# 1.0 LIBRARIES ----

library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing

# 1.1 COLLECT PRODUCT FAMILIES ----

url_home <- "https://www.rosebikes.com/"

# Read in the HTML for the entire webpage
html_home <- read_html(url_home)

# Web scrape the ids for the families
bike_family_tbl <- html_home %>%
  # Get the nodes for the families ...
  html_nodes(css = ".main-navigation-category-bikes__title .main-navigation-category-bikes-level-3__list-item:nth-child(1) .main-navigation-item__title") %>%
  # ...and extract the information of the id attribute
  html_text()

# Print the bike_family_tbl
print(bike_family_tbl)





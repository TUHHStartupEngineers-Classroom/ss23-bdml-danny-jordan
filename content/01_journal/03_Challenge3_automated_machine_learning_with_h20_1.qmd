---
title: "Automated Machine Learning with H20 (I) & (II)"
author: "Danny Jordan"
---


```{r}
#install.packages("h2o")
library(h2o)

# To launch H2O locally with default initialization arguments, use the following: 
h2o.init()

```



# Challenge 3 Automated Machine Learning with H2O (I)

1. Compensation Features-
What can you deduce about the interaction between Monthly Income and Attrition? 
c. Those that are leaving have a lower Monthly Income

2. Compensation Features-
What can you deduce about the interaction between Percent Salary Hike and Attrition?
c. Those that are leaving have lower Percent Salary Hike

3. Compensation Features-
What can you deduce about the interaction between Stock Option Level and Attrition?
b. Those that are staying have a higher stock option level

4. Survey Results-
What can you deduce about the interaction between Environment Satisfaction and Attrition?
A higher proportion of those leaving have a low environment satisfaction level

5. Survey Results
What can you deduce about the interaction between Work Life Balance and Attrition
b. Those that are staying have a higher density of 2's and 3's

6. Performance Data-
What Can you deduce about the interaction between Job Involvement and Attrition?
a. Those that are leaving have a lower density of 3's and 4's

7. Work-Life Features-
What can you deduce about the interaction between Over Time and Attrition?
b. The proportion of those staying that are working Over Time are high compared to those that are not staying

8. Training and Education-
What can you deduce about the interaction between Training Times Last Year and Attrition
b. People that leave tend to have less annual trainings

9. Time-Based Features-
What can you deduce about the interaction between Years At Company and Attrition
b. People that leave tend to have less working years at the company

10. Time-Based Features-
What can you deduce about the interaction between Years Since Last Promotion and Attrition?
a. Those that are leaving have more years since last promotion than those that are staying

##  1. Load the training & test dataset
```{r}

# Required Libraries
library(tidyverse)
library(readxl)
library(purrr)
library(dplyr)
library(recipes)
library(rsample)
library(h2o)


# Initialize H2O
h2o_connection <- h2o.init()

# Read and Split Data
product_backorders_tbl <- read_csv("C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/product_backorders.csv")
#test print
#product_backorders_tbl
set_seed <- 1113
split_obj <- rsample::initial_split(product_backorders_tbl, prop = 0.85)
train_data_tbl <- training(split_obj)
test_data_tbl <- testing(split_obj)

# Data Preparation
recipe_obj <- recipe(went_on_backorder ~ ., data = train_data_tbl) %>%
  step_zv(all_predictors()) %>%
  prep()

train_prepared_tbl <- bake(recipe_obj, new_data = train_data_tbl)
test_prepared_tbl <- bake(recipe_obj, new_data = test_data_tbl)
#train_prepared_tbl
#test_prepared_tbl
```

##  2.Specifiy the response and predictor variables

```{r}


# Divide the data into a training and a validation data frame
# The seed is set for the sake of reproducibility
split_h2o <- h2o.splitFrame(as.h2o(train_prepared_tbl), ratios = c(0.85), seed = 1234)
train_h2o <- split_h2o[[1]]
valid_h2o <- split_h2o[[2]]
test_h2o  <- as.h2o(test_prepared_tbl)

# Define the response variable
target_variable <- "went_on_backorder"

# Define the predictor variables
feature_variables <- setdiff(names(train_h2o), target_variable)

```


## 3 run AutoML specifying the stopping criterion
```{r}
# Run automated machine learning
automl_model_h2o <- h2o.automl(
  x = feature_variables,
  y = target_variable,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs = 30,
  nfolds = 5
)
#train_h2o
#valid_h2o
#test_h2o
# Check the type of the automl_model_h2o object
model_type <- typeof(automl_model_h2o)

#model_type
```


## 4. View the leaderboard 5.Save the leader model 6.Load the model


```{r}
# Get the names of slots in the automl_models_h2o object
slots <- slotNames(automl_model_h2o)

# Access the leaderboard from the automl_models_h2o object
leaderboard <- automl_model_h2o@leaderboard
leaderboard

```

```{r}
# Extract the name of a specific model from the leaderboard
get_model_name <- function(h2o_leaderboard, n = 1, verbose = T) {
  
  model_name <- h2o_leaderboard %>%
    as_tibble() %>%
    slice(n) %>%
    pull(model_id)
  
  if (verbose) message(model_name)
  
  return(model_name)
  
}

# Get the name of the 6th model in the leaderboard
model_name <- automl_model_h2o@leaderboard %>% 
  get_model_name(1) %>% 
  h2o.getModel()

# Save the specified model
#h2o.getModel("StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046") %>% 
#h2o.saveModel(path = "C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/")


# Load a specific model
loaded_model <- h2o.loadModel("C:/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/Challeng3_automated_machine_learning_h2O/StackedEnsemble_BestOfFamily_3_AutoML_2_20230615_64046")
```


## 5.Predicting using Leader Model
```{r}

# Generate predictions using the Stacked Ensemble model
predictions <- h2o.predict(loaded_model, newdata = as.h2o(test_h2o))

# Check the type of the predictions object
pred_type <- typeof(predictions)

# Convert predictions to a tibble
predictions_tbl <- as_tibble(predictions)
saveRDS(predictions_tbl, "/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/predictions_tbl.rds")
View(predictions_tbl)

knitr::include_graphics("/Users/jorda/OneDrive/Dokumente/GitHub/ss23-bdml-danny-jordan/went_back_prediction.png")
```



